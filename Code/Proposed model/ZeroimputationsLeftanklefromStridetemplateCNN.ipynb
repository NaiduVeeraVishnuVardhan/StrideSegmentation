{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58KV6M2z5Q5N",
        "outputId": "235b4278-2fb3-4a6e-f080-e093dfe349a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd \n",
        "import keras \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from tensorflow import keras\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Load the Dataset***"
      ],
      "metadata": {
        "id": "R2c2uEXVDPM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset/test/Datasetfor1peakszeroimputations (1).csv')\n",
        "df = df.iloc[38:]"
      ],
      "metadata": {
        "id": "4Hvff8AvBVpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df.tail(145).index, inplace = True) "
      ],
      "metadata": {
        "id": "lWh_qeO8BVy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##finding the index and the max of consecutive 1's\n",
        "arr = list(df['label'])\n",
        "count = 0\n",
        "prev = 0\n",
        "indexend = 0\n",
        "for i in range(0,len(arr)):\n",
        "    if arr[i] == 1:\n",
        "        count += 1\n",
        "    else:            \n",
        "      if count > prev:\n",
        "        prev = count\n",
        "        indexend = i\n",
        "      count = 0\n",
        "\n",
        "print(\"The longest sequence of 1's is \"+str(prev))\n",
        "print(\"index start at: \"+ str(indexend-prev))\n",
        "print(\"index ends at: \"+ str(indexend-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPIF6dafs32S",
        "outputId": "df91f461-40b1-4e55-8a34-44e8abbd0fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest sequence of 1's is 128\n",
            "index start at: 137895\n",
            "index ends at: 138022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***TRAIN DATASET***"
      ],
      "metadata": {
        "id": "aBKW1DkkDUAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import find_peaks\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "df['label'] = df['label'].astype('category')\n",
        "df['label'] = df['label'].cat.codes\n",
        "df['subj_id'] = df['subj_id'].astype('category')   \n",
        "df['subj_id'] = df['subj_id'].cat.codes             "
      ],
      "metadata": {
        "id": "LWARx1vhsYSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.subj_id.unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibos-_A8Dntg",
        "outputId": "7313737c-11a9-4259-c315-6c8d06675d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKJRMkhPSNLC"
      },
      "outputs": [],
      "source": [
        "# df_train =  df[df.subj_id.isin( df.subj_id.unique()[:25] ) ]  #selecting 25 subjects for training\n",
        "#Seventy percent for training data - 96831 but took 97004 so its 70.0125 so i.e., out of 477 whole strides 334 full strides are selected - which is 668 left and right combined strides. \n",
        "df_train = df.loc[:97004] \n",
        "\n",
        "# WINDOWING WITH NON OVERLAPPING WINDOWS with size 145\n",
        "xs = []\n",
        "ys = []\n",
        "zs = []\n",
        "train_labels = []\n",
        "new_list = []\n",
        "window_size = 145\n",
        "step_size = 145\n",
        "\n",
        "for i in range(0, df.shape[0] - window_size, step_size):\n",
        "  xs = df['x'].values[i: i + 145]\n",
        "  ys = df['y'].values[i: i + 145]\n",
        "  zs = df['z'].values[i: i + 145]\n",
        "\n",
        "  label = df['label'].values[i: i + 145][0] \n",
        "  a = np.c_[ xs,ys,zs ]\n",
        "  new_list.append(a)\n",
        "  train_labels.append(label)\n",
        "\n",
        "train_x = np.asarray(new_list)\n",
        "train_y = np.asarray(train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***TEST DATA***"
      ],
      "metadata": {
        "id": "9rtuYysgENWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_test =  df[df.subj_id.isin( df.subj_id.unique()[25:] ) ]  #selecting 6 subjects for testing\n",
        "# df_test =  df[df.subj_id.isin( df.subj_id.unique()[25:] ) ]  #selecting 6 subjects for testing\n",
        "df_test = df.loc[97004:] #30percent \n",
        "xs = []\n",
        "ys = []\n",
        "zs = []\n",
        "test_labels = []\n",
        "new_list = []\n",
        "window_size = 145\n",
        "step_size = 145\n",
        "\n",
        "for i in range(0, df_test.shape[0] - window_size, step_size):\n",
        "  xs = df_test['x'].values[i: i + 145]\n",
        "  ys = df_test['y'].values[i: i + 145]\n",
        "  zs = df_test['z'].values[i: i + 145]\n",
        "\n",
        "  label = df_test['label'].values[i: i + 145][0] \n",
        "  a = np.c_[ xs,ys,zs ]\n",
        "  new_list.append(a)\n",
        "  test_labels.append(label)\n",
        "\n",
        "test_x = np.asarray(new_list)\n",
        "test_y = np.asarray(test_labels)"
      ],
      "metadata": {
        "id": "wZBT_IWX90g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***EVALUATION***"
      ],
      "metadata": {
        "id": "RrPI7z9xFCTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CNN***"
      ],
      "metadata": {
        "id": "DMRrwcXsEGyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "x_-wwD5S4XDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy 56\n",
        "\n",
        "from keras.regularizers import l2\n",
        "\n",
        "model_cnn3 = Sequential() \n",
        "\n",
        "model_cnn3.add(Conv1D(filters=160, kernel_size=2, activation='relu', input_shape=(145,3), kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\n",
        "model_cnn3.add(Conv1D(filters=128, kernel_size=2, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\n",
        "model_cnn3.add(Flatten())\n",
        "model_cnn3.add(Dropout(0.7))\n",
        "\n",
        "model_cnn3.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model_cnn3.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "model_cnn3.summary()\n",
        "\n",
        "#_________\n",
        "model_cnn3.fit(train_x, train_y, epochs=50, batch_size=1000, verbose=1)\n",
        "#________\n",
        "scores = model_cnn3.evaluate(test_x,test_y, verbose=1)\n",
        " \n",
        "print(scores) "
      ],
      "metadata": {
        "id": "kgXGJSnX8PFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80af460-3363-4a97-ebfc-ade59672ceec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 144, 160)          1120      \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 143, 128)          41088     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 18304)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 18304)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 18305     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,513\n",
            "Trainable params: 60,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 9s 9s/step - loss: 2.1733 - accuracy: 0.5168 - recall: 0.4664 - precision: 0.5187\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0457 - accuracy: 0.8813 - recall: 0.8025 - precision: 0.9526\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9249 - accuracy: 0.9811 - recall: 0.9685 - precision: 0.9935\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.8098 - accuracy: 0.9874 - recall: 0.9832 - precision: 0.9915\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.7050 - accuracy: 0.9916 - recall: 0.9895 - precision: 0.9937\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6030 - accuracy: 0.9937 - recall: 0.9895 - precision: 0.9979\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.5129 - accuracy: 0.9926 - recall: 0.9874 - precision: 0.9979\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.4345 - accuracy: 0.9916 - recall: 0.9853 - precision: 0.9979\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.3659 - accuracy: 0.9916 - recall: 0.9874 - precision: 0.9958\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.3084 - accuracy: 0.9937 - recall: 0.9916 - precision: 0.9958\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.2585 - accuracy: 0.9916 - recall: 0.9895 - precision: 0.9937\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.2151 - accuracy: 0.9926 - recall: 0.9895 - precision: 0.9958\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.1776 - accuracy: 0.9895 - recall: 0.9874 - precision: 0.9916\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1440 - accuracy: 0.9926 - recall: 0.9874 - precision: 0.9979\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1100 - accuracy: 0.9926 - recall: 0.9874 - precision: 0.9979\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0806 - accuracy: 0.9905 - recall: 0.9874 - precision: 0.9937\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.0505 - accuracy: 0.9926 - recall: 0.9874 - precision: 0.9979\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0215 - accuracy: 0.9905 - recall: 0.9853 - precision: 0.9958\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.9905 - accuracy: 0.9947 - recall: 0.9916 - precision: 0.9979\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.9629 - accuracy: 0.9937 - recall: 0.9895 - precision: 0.9979\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.9361 - accuracy: 0.9947 - recall: 0.9916 - precision: 0.9979\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.9101 - accuracy: 0.9937 - recall: 0.9916 - precision: 0.9958\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.8836 - accuracy: 0.9947 - recall: 0.9916 - precision: 0.9979\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.8574 - accuracy: 0.9926 - recall: 0.9895 - precision: 0.9958\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.8326 - accuracy: 0.9947 - recall: 0.9916 - precision: 0.9979\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.8085 - accuracy: 0.9926 - recall: 0.9895 - precision: 0.9958\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7824 - accuracy: 0.9947 - recall: 0.9916 - precision: 0.9979\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7584 - accuracy: 0.9947 - recall: 0.9916 - precision: 0.9979\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7342 - accuracy: 0.9937 - recall: 0.9895 - precision: 0.9979\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7129 - accuracy: 0.9947 - recall: 0.9916 - precision: 0.9979\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6912 - accuracy: 0.9947 - recall: 0.9916 - precision: 0.9979\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6681 - accuracy: 0.9947 - recall: 0.9916 - precision: 0.9979\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6483 - accuracy: 0.9937 - recall: 0.9895 - precision: 0.9979\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6274 - accuracy: 0.9947 - recall: 0.9937 - precision: 0.9958\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6090 - accuracy: 0.9947 - recall: 0.9937 - precision: 0.9958\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5885 - accuracy: 0.9937 - recall: 0.9916 - precision: 0.9958\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5705 - accuracy: 0.9958 - recall: 0.9937 - precision: 0.9979\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5526 - accuracy: 0.9947 - recall: 0.9958 - precision: 0.9937\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5359 - accuracy: 0.9958 - recall: 0.9937 - precision: 0.9979\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5181 - accuracy: 0.9947 - recall: 0.9916 - precision: 0.9979\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5020 - accuracy: 0.9947 - recall: 0.9916 - precision: 0.9979\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4860 - accuracy: 0.9958 - recall: 0.9937 - precision: 0.9979\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4716 - accuracy: 0.9958 - recall: 0.9937 - precision: 0.9979\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4558 - accuracy: 0.9958 - recall: 0.9937 - precision: 0.9979\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4428 - accuracy: 0.9926 - recall: 0.9916 - precision: 0.9937\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4285 - accuracy: 0.9968 - recall: 0.9937 - precision: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4141 - accuracy: 0.9968 - recall: 0.9958 - precision: 0.9979\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4026 - accuracy: 0.9968 - recall: 0.9958 - precision: 0.9979\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3904 - accuracy: 0.9947 - recall: 0.9937 - precision: 0.9958\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3772 - accuracy: 0.9968 - recall: 0.9958 - precision: 0.9979\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.1973 - accuracy: 0.5385 - recall: 0.9412 - precision: 0.4848\n",
            "[2.197310209274292, 0.5384615659713745, 0.9411764740943909, 0.4848484992980957]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***EXP***"
      ],
      "metadata": {
        "id": "FSfTzBIn93LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "rlrop = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=100)\n",
        "\n",
        "model_cnn4 = Sequential() \n",
        "model_cnn4.add(Conv1D(filters=160, kernel_size=2, activation='relu', input_shape=(145,3), kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model_cnn4.add(Conv1D(filters=128, kernel_size=2, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model_cnn4.add(Flatten())\n",
        "model_cnn4.add(Dropout(0.7))\n",
        "model_cnn4.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model_cnn4.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "model_cnn4.summary()\n",
        "\n",
        "#_________\n",
        "model_cnn4.fit(train_x, train_y, epochs=50, batch_size=1000, verbose=1,callbacks=[rlrop])\n",
        "#________\n",
        "scores = model_cnn4.evaluate(test_x,test_y, verbose=1)\n",
        "scores"
      ],
      "metadata": {
        "id": "s9_eRiFm92KG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd5e8cd-9ee7-4f27-fe7c-27d17c15f69e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_2 (Conv1D)           (None, 144, 160)          1120      \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 143, 128)          41088     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 18304)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 18304)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 18305     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,513\n",
            "Trainable params: 60,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 2.1763 - accuracy: 0.5546 - recall_1: 0.3340 - precision_1: 0.5977 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0593 - accuracy: 0.8561 - recall_1: 0.7458 - precision_1: 0.9569 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9491 - accuracy: 0.9716 - recall_1: 0.9496 - precision_1: 0.9934 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.8466 - accuracy: 0.9874 - recall_1: 0.9790 - precision_1: 0.9957 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.7436 - accuracy: 0.9905 - recall_1: 0.9853 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6408 - accuracy: 0.9916 - recall_1: 0.9874 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.5438 - accuracy: 0.9905 - recall_1: 0.9853 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.4604 - accuracy: 0.9926 - recall_1: 0.9916 - precision_1: 0.9937 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.3883 - accuracy: 0.9926 - recall_1: 0.9895 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.3245 - accuracy: 0.9895 - recall_1: 0.9895 - precision_1: 0.9895 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.2719 - accuracy: 0.9926 - recall_1: 0.9895 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.2271 - accuracy: 0.9895 - recall_1: 0.9874 - precision_1: 0.9916 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1881 - accuracy: 0.9905 - recall_1: 0.9853 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.1516 - accuracy: 0.9916 - recall_1: 0.9853 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.1207 - accuracy: 0.9905 - recall_1: 0.9895 - precision_1: 0.9916 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.0909 - accuracy: 0.9916 - recall_1: 0.9874 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.0602 - accuracy: 0.9937 - recall_1: 0.9895 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.0315 - accuracy: 0.9916 - recall_1: 0.9853 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0031 - accuracy: 0.9926 - recall_1: 0.9895 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.9737 - accuracy: 0.9916 - recall_1: 0.9895 - precision_1: 0.9937 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.9454 - accuracy: 0.9937 - recall_1: 0.9916 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.9200 - accuracy: 0.9926 - recall_1: 0.9895 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.8941 - accuracy: 0.9937 - recall_1: 0.9895 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.8686 - accuracy: 0.9926 - recall_1: 0.9895 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.8408 - accuracy: 0.9947 - recall_1: 0.9937 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.8185 - accuracy: 0.9926 - recall_1: 0.9895 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7922 - accuracy: 0.9937 - recall_1: 0.9916 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7689 - accuracy: 0.9926 - recall_1: 0.9895 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7440 - accuracy: 0.9947 - recall_1: 0.9916 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7217 - accuracy: 0.9947 - recall_1: 0.9916 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7006 - accuracy: 0.9926 - recall_1: 0.9895 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6765 - accuracy: 0.9947 - recall_1: 0.9916 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6568 - accuracy: 0.9947 - recall_1: 0.9937 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6365 - accuracy: 0.9947 - recall_1: 0.9937 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6183 - accuracy: 0.9947 - recall_1: 0.9916 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5958 - accuracy: 0.9937 - recall_1: 0.9937 - precision_1: 0.9937 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5785 - accuracy: 0.9926 - recall_1: 0.9874 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5605 - accuracy: 0.9947 - recall_1: 0.9916 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5405 - accuracy: 0.9958 - recall_1: 0.9937 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5247 - accuracy: 0.9958 - recall_1: 0.9937 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5086 - accuracy: 0.9958 - recall_1: 0.9958 - precision_1: 0.9958 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4926 - accuracy: 0.9968 - recall_1: 0.9958 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4763 - accuracy: 0.9968 - recall_1: 0.9958 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4619 - accuracy: 0.9968 - recall_1: 0.9958 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4471 - accuracy: 0.9968 - recall_1: 0.9958 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4339 - accuracy: 0.9958 - recall_1: 0.9937 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4208 - accuracy: 0.9958 - recall_1: 0.9937 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.4067 - accuracy: 0.9968 - recall_1: 0.9958 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3953 - accuracy: 0.9958 - recall_1: 0.9937 - precision_1: 0.9979 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3821 - accuracy: 0.9968 - recall_1: 0.9958 - precision_1: 0.9979 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.2108 - accuracy: 0.5641 - recall_1: 0.9412 - precision_1: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.2107973098754883, 0.5641025900840759, 0.9411764740943909, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***EXP7***"
      ],
      "metadata": {
        "id": "R2Wxpn4d_p3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "# import noise layer\n",
        "from keras.layers import GaussianNoise\n",
        "# define noise layer\n",
        "layer = GaussianNoise(0.1)\n",
        "\n",
        "model_cnn6 = Sequential() \n",
        "model_cnn6.add(Conv1D(filters=160, kernel_size=2, activation='relu', input_shape=(145,3) , kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model_cnn6.add(GaussianNoise(0.1))\n",
        "model_cnn6.add(Conv1D(filters=128, kernel_size=2, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model_cnn6.add(GaussianNoise(0.1))\n",
        "model_cnn6.add(Flatten())\n",
        "model_cnn6.add(Dropout(0.7))\n",
        "model_cnn6.add(GaussianNoise(0.1))\n",
        "model_cnn6.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model_cnn6.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "model_cnn6.summary()\n",
        "\n",
        "#_________\n",
        "model_cnn6.fit(train_x, train_y, epochs=50, batch_size=1000, verbose=1, validation_split=0.2)\n",
        "#________\n",
        "scores = model_cnn6.evaluate(test_x,test_y, verbose=1)\n",
        " \n",
        "scores "
      ],
      "metadata": {
        "id": "8hwycoDh_o7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5244d9-6a56-4223-f5bf-d9b79ded57e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_12 (Conv1D)          (None, 144, 160)          1120      \n",
            "                                                                 \n",
            " gaussian_noise_15 (Gaussian  (None, 144, 160)         0         \n",
            " Noise)                                                          \n",
            "                                                                 \n",
            " conv1d_13 (Conv1D)          (None, 143, 128)          41088     \n",
            "                                                                 \n",
            " gaussian_noise_16 (Gaussian  (None, 143, 128)         0         \n",
            " Noise)                                                          \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 18304)             0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 18304)             0         \n",
            "                                                                 \n",
            " gaussian_noise_17 (Gaussian  (None, 18304)            0         \n",
            " Noise)                                                          \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 18305     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,513\n",
            "Trainable params: 60,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.2095 - accuracy: 0.4652 - recall_6: 0.4079 - precision_6: 0.4599 - val_loss: 2.0842 - val_accuracy: 0.7382 - val_recall_6: 0.9792 - val_precision_6: 0.6620\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.0937 - accuracy: 0.6373 - recall_6: 0.6342 - precision_6: 0.6376 - val_loss: 2.0031 - val_accuracy: 0.9215 - val_recall_6: 0.9792 - val_precision_6: 0.8785\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.9863 - accuracy: 0.7530 - recall_6: 0.7842 - precision_6: 0.7376 - val_loss: 1.9239 - val_accuracy: 0.9843 - val_recall_6: 0.9792 - val_precision_6: 0.9895\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.8818 - accuracy: 0.8633 - recall_6: 0.8763 - precision_6: 0.8538 - val_loss: 1.8459 - val_accuracy: 0.9843 - val_recall_6: 0.9792 - val_precision_6: 0.9895\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.7876 - accuracy: 0.9041 - recall_6: 0.9158 - precision_6: 0.8946 - val_loss: 1.7689 - val_accuracy: 0.9843 - val_recall_6: 0.9792 - val_precision_6: 0.9895\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.6869 - accuracy: 0.9461 - recall_6: 0.9526 - precision_6: 0.9403 - val_loss: 1.6935 - val_accuracy: 0.9843 - val_recall_6: 0.9792 - val_precision_6: 0.9895\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.5983 - accuracy: 0.9514 - recall_6: 0.9763 - precision_6: 0.9298 - val_loss: 1.6202 - val_accuracy: 0.9843 - val_recall_6: 0.9792 - val_precision_6: 0.9895\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.5131 - accuracy: 0.9632 - recall_6: 0.9868 - precision_6: 0.9422 - val_loss: 1.5492 - val_accuracy: 0.9843 - val_recall_6: 0.9792 - val_precision_6: 0.9895\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.4356 - accuracy: 0.9777 - recall_6: 0.9921 - precision_6: 0.9642 - val_loss: 1.4813 - val_accuracy: 0.9843 - val_recall_6: 0.9792 - val_precision_6: 0.9895\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.3738 - accuracy: 0.9855 - recall_6: 0.9921 - precision_6: 0.9792 - val_loss: 1.4167 - val_accuracy: 0.9843 - val_recall_6: 0.9792 - val_precision_6: 0.9895\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.3079 - accuracy: 0.9921 - recall_6: 0.9974 - precision_6: 0.9870 - val_loss: 1.3559 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.2586 - accuracy: 0.9908 - recall_6: 0.9921 - precision_6: 0.9895 - val_loss: 1.2993 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.2159 - accuracy: 0.9934 - recall_6: 0.9921 - precision_6: 0.9947 - val_loss: 1.2474 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.1724 - accuracy: 0.9947 - recall_6: 0.9921 - precision_6: 0.9974 - val_loss: 1.2004 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.1349 - accuracy: 0.9961 - recall_6: 0.9947 - precision_6: 0.9974 - val_loss: 1.1582 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.0991 - accuracy: 0.9921 - recall_6: 0.9921 - precision_6: 0.9921 - val_loss: 1.1206 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.0617 - accuracy: 0.9947 - recall_6: 0.9921 - precision_6: 0.9974 - val_loss: 1.0866 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.0355 - accuracy: 0.9921 - recall_6: 0.9895 - precision_6: 0.9947 - val_loss: 1.0554 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.0043 - accuracy: 0.9947 - recall_6: 0.9895 - precision_6: 1.0000 - val_loss: 1.0265 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.9752 - accuracy: 0.9961 - recall_6: 0.9921 - precision_6: 1.0000 - val_loss: 0.9990 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.9491 - accuracy: 0.9947 - recall_6: 0.9921 - precision_6: 0.9974 - val_loss: 0.9726 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.9229 - accuracy: 0.9947 - recall_6: 0.9895 - precision_6: 1.0000 - val_loss: 0.9470 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.8986 - accuracy: 0.9961 - recall_6: 0.9921 - precision_6: 1.0000 - val_loss: 0.9219 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.8699 - accuracy: 0.9947 - recall_6: 0.9921 - precision_6: 0.9974 - val_loss: 0.8974 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.8444 - accuracy: 0.9961 - recall_6: 0.9921 - precision_6: 1.0000 - val_loss: 0.8734 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.8225 - accuracy: 0.9947 - recall_6: 0.9921 - precision_6: 0.9974 - val_loss: 0.8498 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7983 - accuracy: 0.9961 - recall_6: 0.9921 - precision_6: 1.0000 - val_loss: 0.8266 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7780 - accuracy: 0.9961 - recall_6: 0.9947 - precision_6: 0.9974 - val_loss: 0.8038 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7497 - accuracy: 0.9961 - recall_6: 0.9921 - precision_6: 1.0000 - val_loss: 0.7815 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7308 - accuracy: 0.9947 - recall_6: 0.9921 - precision_6: 0.9974 - val_loss: 0.7595 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7116 - accuracy: 0.9961 - recall_6: 0.9921 - precision_6: 1.0000 - val_loss: 0.7381 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6871 - accuracy: 0.9947 - recall_6: 0.9947 - precision_6: 0.9947 - val_loss: 0.7171 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6659 - accuracy: 0.9961 - recall_6: 0.9947 - precision_6: 0.9974 - val_loss: 0.6966 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6466 - accuracy: 0.9961 - recall_6: 0.9947 - precision_6: 0.9974 - val_loss: 0.6765 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6247 - accuracy: 0.9961 - recall_6: 0.9947 - precision_6: 0.9974 - val_loss: 0.6570 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6081 - accuracy: 0.9961 - recall_6: 0.9921 - precision_6: 1.0000 - val_loss: 0.6379 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5881 - accuracy: 0.9947 - recall_6: 0.9947 - precision_6: 0.9947 - val_loss: 0.6194 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5699 - accuracy: 0.9974 - recall_6: 0.9947 - precision_6: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5521 - accuracy: 0.9974 - recall_6: 0.9947 - precision_6: 1.0000 - val_loss: 0.5840 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5359 - accuracy: 0.9961 - recall_6: 0.9947 - precision_6: 0.9974 - val_loss: 0.5671 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5195 - accuracy: 0.9961 - recall_6: 0.9947 - precision_6: 0.9974 - val_loss: 0.5506 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5046 - accuracy: 0.9974 - recall_6: 0.9947 - precision_6: 1.0000 - val_loss: 0.5346 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4883 - accuracy: 0.9974 - recall_6: 0.9947 - precision_6: 1.0000 - val_loss: 0.5192 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4750 - accuracy: 0.9934 - recall_6: 0.9921 - precision_6: 0.9947 - val_loss: 0.5043 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4589 - accuracy: 0.9974 - recall_6: 0.9947 - precision_6: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4445 - accuracy: 0.9974 - recall_6: 0.9947 - precision_6: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4317 - accuracy: 0.9961 - recall_6: 0.9921 - precision_6: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4192 - accuracy: 0.9961 - recall_6: 0.9947 - precision_6: 0.9974 - val_loss: 0.4494 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4047 - accuracy: 0.9974 - recall_6: 0.9947 - precision_6: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3938 - accuracy: 0.9947 - recall_6: 0.9921 - precision_6: 0.9974 - val_loss: 0.4247 - val_accuracy: 0.9791 - val_recall_6: 0.9688 - val_precision_6: 0.9894\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7822 - accuracy: 0.6667 - recall_6: 0.2941 - precision_6: 0.8333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7822399139404297,\n",
              " 0.6666666865348816,\n",
              " 0.29411765933036804,\n",
              " 0.8333333134651184]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "model_cnn7 = Sequential() \n",
        "model_cnn7.add(Conv1D(filters=160, kernel_size=2, activation='relu', input_shape=(145,3) , kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model_cnn7.add(GaussianNoise(0.5))\n",
        "model_cnn7.add(Conv1D(filters=128, kernel_size=2, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model_cnn7.add(GaussianNoise(0.5))\n",
        "# model_cnn7.add(GaussianNoise(0.5))\n",
        "model_cnn7.add(Flatten())\n",
        "model_cnn7.add(Dropout(0.7))\n",
        "model_cnn7.add(GaussianNoise(0.25))\n",
        "model_cnn7.add(Dense(1,activation='sigmoid'))\n",
        "model_cnn7.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "model_cnn7.summary()\n",
        "#_________\n",
        "model_cnn7.fit(train_x, train_y, epochs=50, batch_size=1000, verbose=1, validation_split=0.2)\n",
        "#________\n",
        "scores = model_cnn7.evaluate(test_x,test_y, verbose=1)\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiIX41m9fZ9A",
        "outputId": "0dbd4352-748f-4fe0-a6fd-1ac02bb80d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_10 (Conv1D)          (None, 144, 160)          1120      \n",
            "                                                                 \n",
            " gaussian_noise_11 (Gaussian  (None, 144, 160)         0         \n",
            " Noise)                                                          \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 143, 128)          41088     \n",
            "                                                                 \n",
            " gaussian_noise_12 (Gaussian  (None, 143, 128)         0         \n",
            " Noise)                                                          \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 18304)             0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 18304)             0         \n",
            "                                                                 \n",
            " gaussian_noise_13 (Gaussian  (None, 18304)            0         \n",
            " Noise)                                                          \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 18305     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,513\n",
            "Trainable params: 60,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.4633 - accuracy: 0.4836 - recall_5: 0.5526 - precision_5: 0.4850 - val_loss: 2.1131 - val_accuracy: 0.8325 - val_recall_5: 0.6771 - val_precision_5: 0.9848\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.4380 - accuracy: 0.5204 - recall_5: 0.3026 - precision_5: 0.5349 - val_loss: 2.0815 - val_accuracy: 0.8953 - val_recall_5: 0.9896 - val_precision_5: 0.8333\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.4221 - accuracy: 0.4744 - recall_5: 0.6053 - precision_5: 0.4792 - val_loss: 2.0455 - val_accuracy: 0.9372 - val_recall_5: 0.9896 - val_precision_5: 0.8962\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.2880 - accuracy: 0.5493 - recall_5: 0.6658 - precision_5: 0.5394 - val_loss: 2.0081 - val_accuracy: 0.9738 - val_recall_5: 0.9792 - val_precision_5: 0.9691\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.2340 - accuracy: 0.5572 - recall_5: 0.5053 - precision_5: 0.5630 - val_loss: 1.9723 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.2166 - accuracy: 0.5532 - recall_5: 0.4474 - precision_5: 0.5667 - val_loss: 1.9374 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.2054 - accuracy: 0.5348 - recall_5: 0.5184 - precision_5: 0.5353 - val_loss: 1.9022 - val_accuracy: 0.9843 - val_recall_5: 0.9792 - val_precision_5: 0.9895\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.0884 - accuracy: 0.5966 - recall_5: 0.6053 - precision_5: 0.5943 - val_loss: 1.8662 - val_accuracy: 0.9843 - val_recall_5: 0.9792 - val_precision_5: 0.9895\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.1099 - accuracy: 0.5742 - recall_5: 0.6421 - precision_5: 0.5648 - val_loss: 1.8290 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.9681 - accuracy: 0.6347 - recall_5: 0.6474 - precision_5: 0.6308 - val_loss: 1.7909 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.9401 - accuracy: 0.6518 - recall_5: 0.6684 - precision_5: 0.6463 - val_loss: 1.7519 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.8780 - accuracy: 0.6544 - recall_5: 0.6474 - precision_5: 0.6560 - val_loss: 1.7126 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.7902 - accuracy: 0.6938 - recall_5: 0.6447 - precision_5: 0.7143 - val_loss: 1.6726 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.8384 - accuracy: 0.6675 - recall_5: 0.6158 - precision_5: 0.6862 - val_loss: 1.6315 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.7125 - accuracy: 0.7280 - recall_5: 0.7000 - precision_5: 0.7409 - val_loss: 1.5899 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.6745 - accuracy: 0.7516 - recall_5: 0.7816 - precision_5: 0.7370 - val_loss: 1.5476 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.6123 - accuracy: 0.7779 - recall_5: 0.8053 - precision_5: 0.7631 - val_loss: 1.5049 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.5547 - accuracy: 0.7924 - recall_5: 0.8184 - precision_5: 0.7775 - val_loss: 1.4618 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.5276 - accuracy: 0.7950 - recall_5: 0.7921 - precision_5: 0.7963 - val_loss: 1.4185 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.4452 - accuracy: 0.8384 - recall_5: 0.8500 - precision_5: 0.8303 - val_loss: 1.3754 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.4136 - accuracy: 0.8581 - recall_5: 0.8395 - precision_5: 0.8716 - val_loss: 1.3325 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.3405 - accuracy: 0.8817 - recall_5: 0.8658 - precision_5: 0.8940 - val_loss: 1.2900 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.3260 - accuracy: 0.8633 - recall_5: 0.8579 - precision_5: 0.8670 - val_loss: 1.2483 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.2624 - accuracy: 0.8988 - recall_5: 0.8947 - precision_5: 0.9019 - val_loss: 1.2078 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.2383 - accuracy: 0.9106 - recall_5: 0.9079 - precision_5: 0.9127 - val_loss: 1.1689 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.1383 - accuracy: 0.9474 - recall_5: 0.9579 - precision_5: 0.9381 - val_loss: 1.1323 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.1422 - accuracy: 0.9396 - recall_5: 0.9368 - precision_5: 0.9418 - val_loss: 1.0977 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.0962 - accuracy: 0.9369 - recall_5: 0.9632 - precision_5: 0.9150 - val_loss: 1.0652 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.0754 - accuracy: 0.9448 - recall_5: 0.9553 - precision_5: 0.9356 - val_loss: 1.0351 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.0336 - accuracy: 0.9593 - recall_5: 0.9711 - precision_5: 0.9486 - val_loss: 1.0074 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.0064 - accuracy: 0.9619 - recall_5: 0.9737 - precision_5: 0.9512 - val_loss: 0.9819 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.9785 - accuracy: 0.9698 - recall_5: 0.9711 - precision_5: 0.9685 - val_loss: 0.9587 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.9493 - accuracy: 0.9750 - recall_5: 0.9711 - precision_5: 0.9788 - val_loss: 0.9374 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.9236 - accuracy: 0.9803 - recall_5: 0.9763 - precision_5: 0.9841 - val_loss: 0.9175 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.9011 - accuracy: 0.9842 - recall_5: 0.9816 - precision_5: 0.9868 - val_loss: 0.8989 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.8816 - accuracy: 0.9816 - recall_5: 0.9684 - precision_5: 0.9946 - val_loss: 0.8812 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.8590 - accuracy: 0.9829 - recall_5: 0.9789 - precision_5: 0.9867 - val_loss: 0.8641 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.8344 - accuracy: 0.9869 - recall_5: 0.9868 - precision_5: 0.9868 - val_loss: 0.8476 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.8160 - accuracy: 0.9908 - recall_5: 0.9921 - precision_5: 0.9895 - val_loss: 0.8316 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7915 - accuracy: 0.9908 - recall_5: 0.9895 - precision_5: 0.9921 - val_loss: 0.8158 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7862 - accuracy: 0.9895 - recall_5: 0.9895 - precision_5: 0.9895 - val_loss: 0.8002 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7671 - accuracy: 0.9882 - recall_5: 0.9921 - precision_5: 0.9843 - val_loss: 0.7849 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7487 - accuracy: 0.9895 - recall_5: 0.9895 - precision_5: 0.9895 - val_loss: 0.7698 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7315 - accuracy: 0.9895 - recall_5: 0.9947 - precision_5: 0.9844 - val_loss: 0.7549 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.7097 - accuracy: 0.9934 - recall_5: 0.9947 - precision_5: 0.9921 - val_loss: 0.7403 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.7025 - accuracy: 0.9921 - recall_5: 0.9947 - precision_5: 0.9895 - val_loss: 0.7259 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6870 - accuracy: 0.9895 - recall_5: 0.9868 - precision_5: 0.9921 - val_loss: 0.7117 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6645 - accuracy: 0.9908 - recall_5: 0.9895 - precision_5: 0.9921 - val_loss: 0.6976 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6584 - accuracy: 0.9921 - recall_5: 0.9921 - precision_5: 0.9921 - val_loss: 0.6838 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.6440 - accuracy: 0.9895 - recall_5: 0.9947 - precision_5: 0.9844 - val_loss: 0.6701 - val_accuracy: 0.9791 - val_recall_5: 0.9688 - val_precision_5: 0.9894\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.4946 - accuracy: 0.6923 - recall_5: 0.2941 - precision_5: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.49460768699646, 0.692307710647583, 0.29411765933036804, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix in sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "Gwz93a8irL1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual = test_y \n",
        "pred = model_cnn7.predict(test_x) \n",
        "predicted = np.argmax(pred, axis = 1)"
      ],
      "metadata": {
        "id": "qEBnphAnrkhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "matrix = confusion_matrix(actual,predicted, labels=[1,0])\n",
        "print('Confusion matrix : \\n',matrix)\n",
        "\n",
        "# outcome values order in sklearn\n",
        "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
        "print('Outcome values : \\n', tp, fn, fp, tn)\n",
        "\n",
        "# classification report for precision, recall f1-score and accuracy\n",
        "matrix = classification_report(actual,predicted,labels=[1,0])\n",
        "print('Classification report : \\n',matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1N2506Ef52J",
        "outputId": "c590bb98-4ea5-4a43-a355-9497829e5d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix : \n",
            " [[ 87  59]\n",
            " [ 29 109]]\n",
            "Outcome values : \n",
            " 87 59 29 109\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.75      0.60      0.66       146\n",
            "           0       0.65      0.79      0.71       138\n",
            "\n",
            "    accuracy                           0.69       284\n",
            "   macro avg       0.70      0.69      0.69       284\n",
            "weighted avg       0.70      0.69      0.69       284\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "fpr, tpr, threshold = metrics.roc_curve(actual, predicted)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        " \n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "AVhP6Bkus-5w",
        "outputId": "80f5768a-2b37-47b2-c52e-9d342a9f585a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "ZeroimputationsLeftanklefromStridetemplateCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}