{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58KV6M2z5Q5N",
        "outputId": "307e7b4d-a9b2-4a80-cb53-6a9c371fd2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from tensorflow import keras                                                                                \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Load the Dataset***"
      ],
      "metadata": {
        "id": "R2c2uEXVDPM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset/FinalDatasetWithlabelsP3T15.csv')\n",
        "\n",
        "##finding the index and the max of consecutive 1's\n",
        "arr = list(df['label'])\n",
        "count = 0\n",
        "prev = 0\n",
        "indexend = 0\n",
        "for i in range(0,len(arr)):\n",
        "    if arr[i] == 1:\n",
        "        count += 1\n",
        "    else:            \n",
        "      if count > prev:\n",
        "        prev = count\n",
        "        indexend = i\n",
        "      count = 0\n",
        "\n",
        "print(\"The longest sequence of 1's is \"+str(prev))\n",
        "print(\"index start at: \"+ str(indexend-prev))\n",
        "print(\"index ends at: \"+ str(indexend-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPIF6dafs32S",
        "outputId": "26eeb8fa-f53d-461f-d855-8fc2ea22b7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest sequence of 1's is 152\n",
            "index start at: 2534998\n",
            "index ends at: 2535149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##finding the index and the max of consecutive 0's\n",
        "arr = list(df['label'])\n",
        "count = 0\n",
        "prev = 0\n",
        "indexend = 0\n",
        "for i in range(0,len(arr)):\n",
        "    if arr[i] == 0:\n",
        "        count += 1\n",
        "    else:            \n",
        "      if count > prev:\n",
        "        prev = count\n",
        "        indexend = i\n",
        "      count = 0\n",
        "\n",
        "print(\"The longest sequence of 0's is \"+str(prev))\n",
        "print(\"index start at: \"+ str(indexend-prev))\n",
        "print(\"index ends at: \"+ str(indexend-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qQKWg07whiz",
        "outputId": "f6ef7e8e-7ae9-45ab-98fb-837d5c52c4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest sequence of 0's is 198\n",
            "index start at: 2576265\n",
            "index ends at: 2576462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WAeAkhSJz7rb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***TRAIN DATASET***"
      ],
      "metadata": {
        "id": "aBKW1DkkDUAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import find_peaks\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset/FinalDatasetWithlabelsP3T15.csv')\n",
        "\n",
        "df['label'] = df['label'].astype('category')\n",
        "df['label'] = df['label'].cat.codes\n",
        "df['subj_id'] = df['subj_id'].astype('category')\n",
        "df['subj_id'] = df['subj_id'].cat.codes"
      ],
      "metadata": {
        "id": "LWARx1vhsYSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKJRMkhPSNLC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "d9e896d2-75e0-4cbb-81f7-36915cc256e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IQR, upper bound and lower bound values are :\n",
            "40.0 106.0 -54.0\n"
          ]
        }
      ],
      "source": [
        "df_train =  df[df.subj_id.isin( df.subj_id.unique()[:25] ) ]  #selecting 25 subjects for training\n",
        "\n",
        "#find the peaks\n",
        "x = df_train['magnitude'].values\n",
        "peaks, _ = find_peaks(x, prominence=0.5)\n",
        "peaks = np.insert(peaks, 0, 0, axis=0)\n",
        "\n",
        "############################################################################################\n",
        "def pairwiseDifference(arr, n):\n",
        "  diff =[]\n",
        "  for i in range(n - 1) :\n",
        "    diff.append(abs(arr[i] - arr[i + 1]))\n",
        "  return diff\n",
        "        \n",
        "arr = peaks\n",
        "n = len(arr)\n",
        "#calculationg window sizes.\n",
        "windows = pairwiseDifference(arr, n)\n",
        "\n",
        "#Using boxplot.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#boxplot.\n",
        "plt.boxplot(arr)\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "plt.show()\n",
        "#HISTOGRAM.\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(windows)\n",
        "plt.show()\n",
        "###############################################################################################\n",
        "#Finding the outliers \n",
        "# finding the 1st quartile \n",
        "q1 = np.quantile(windows, 0.25)\n",
        " \n",
        "# finding the 3rd quartile\n",
        "q3 = np.quantile(windows, 0.75)\n",
        "med = np.median(windows)\n",
        " \n",
        "# finding the iqr region\n",
        "iqr = q3-q1\n",
        " \n",
        "# finding upper and lower whiskers\n",
        "upper_bound = q3+(1.5*iqr)\n",
        "lower_bound = q1-(1.5*iqr)\n",
        "print(\"IQR, upper bound and lower bound values are :\")\n",
        "print(iqr, upper_bound, lower_bound)\n",
        "\n",
        "###############################################################################################\n",
        "\n",
        "#Removing and saving the list of dataframes for each stride.\n",
        "list_of_df = []\n",
        "windowsRemoved = []\n",
        "for each in range(0, (len(peaks) - 1), 1  ):\n",
        "  if 54 <= abs(peaks[each + 1]- peaks[each]) <= 106:\n",
        "    list_of_df.append( df.loc[ peaks[each]:(peaks[each  + 1] - 1 ) ] )           \n",
        "  else: \n",
        "    windowsRemoved.append((peaks[each + 1]- peaks[each]))\n",
        "#################################################################################################\n",
        "#zero imputing for each stride.\n",
        "list_of_Zerodf = []\n",
        "for each in range(0, len(list_of_df) ,1 ):\n",
        "  i = np.arange(start= list_of_df[each].shape[0] + 1 , stop=111 )\n",
        "  df_zero = pd.DataFrame(0, index=i, columns=list_of_df[each].columns)\n",
        "  w1 = pd.concat([list_of_df[each],df_zero])  \n",
        "  list_of_Zerodf.append(w1) \n",
        "\n",
        "\n",
        "#dataset after combining zero imputed df's.\n",
        "FinalDataFrame = pd.concat(list_of_Zerodf)\n",
        "\n",
        "\n",
        "# WINDOWING WITH NON OVERLAPPING WINDOWS with size 110\n",
        "xs = []\n",
        "ys = []\n",
        "zs = []\n",
        "train_labels = []\n",
        "new_list = []\n",
        "window_size = 110\n",
        "step_size = 110\n",
        "\n",
        "for i in range(0, FinalDataFrame.shape[0] - window_size, step_size):\n",
        "  xs = FinalDataFrame['x'].values[i: i + 110]\n",
        "  ys = FinalDataFrame['y'].values[i: i + 110]\n",
        "  zs = FinalDataFrame['z'].values[i: i + 110]\n",
        "  label = FinalDataFrame['label'].values[i: i + 110][0] \n",
        "  a = np.c_[ xs,ys,zs ]\n",
        "  new_list.append(a)\n",
        "  train_labels.append(label)\n",
        "\n",
        "train_x = np.asarray(new_list)\n",
        "train_y = np.asarray(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "_a76KeaXExdT",
        "outputId": "bc1a3db5-59f7-4613-c7dc-9cb38fcd7818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8251a6c594ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist_of_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_format_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_user_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_exec_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36mcompute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;31m# This can be set to True by the write_output_prompt method in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-3>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;31m# Special case for 1-item tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    396\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                                 \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_default_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_safe_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_baseclass_reprs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# A user-provided repr. Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0mline_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0mmax_colwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_colwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0mshow_dimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_dimensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m         )\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, min_rows, max_cols, show_dimensions, decimal, line_width, max_colwidth, encoding)\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m                 \u001b[0mline_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m             )\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self, buf, encoding, line_width)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0mstring_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msave_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_string_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_show_dimensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimensions_info\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36m_get_string_representation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_join_multiline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_strcols_to_terminal_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36m_fit_strcols_to_terminal_width\u001b[0;34m(self, strcols)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# and then generate string representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_strcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstrcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36m_get_strcols\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_strcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_truncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_dot_separators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_strcols\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mRender\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0mlists\u001b[0m \u001b[0mof\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \"\"\"\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_strcols_without_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_get_strcols_without_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             )\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             fmt_values = _make_fixed_width(\n\u001b[1;32m    806\u001b[0m                 \u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjustify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_colwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_col\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m             \u001b[0mleading_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m         )\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_array\u001b[0;34m(values, formatter, float_format, na_rep, digits, space, justify, decimal, leading_space, quoting)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfmt_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m         \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_make_fixed_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjustify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_format_strings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result_as_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_result_as_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m             \u001b[0mfloat_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_format\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m         \u001b[0mformatted_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_values_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_width\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_values_with\u001b[0;34m(float_format)\u001b[0m\n\u001b[1;32m   1454\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m             \u001b[0mis_complex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_complex_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_with_na_rep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_width\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_with_na_rep\u001b[0;34m(values, formatter, na_rep)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mformat_with_na_rep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_rep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m             formatted = np.array(\n\u001b[1;32m   1427\u001b[0m                 [\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna\u001b[0;34m(obj, inf_as_na)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mboolean\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mboolean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \"\"\"\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minf_as_na\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlibmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecknull_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***TEST DATA***"
      ],
      "metadata": {
        "id": "9rtuYysgENWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df[df.subj_id.isin( df.subj_id.unique()[25:] )]\n",
        "\n",
        "#find the peaks\n",
        "x = df_test['magnitude'].values\n",
        "peaks, _ = find_peaks(x, prominence=0.5)\n",
        "# peaks = np.insert(peaks, 0, 0, axis=0)\n",
        "############################################################################################\n",
        "def pairwiseDifference(arr, n):\n",
        "  diff =[]\n",
        "  for i in range(n - 1) :\n",
        "    diff.append(abs(arr[i] - arr[i + 1]))\n",
        "  return diff\n",
        "        \n",
        "arr = peaks\n",
        "n = len(arr)\n",
        "#calculationg window sizes.\n",
        "windows = pairwiseDifference(arr, n)\n",
        "\n",
        "#Using boxplot.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#boxplot.\n",
        "plt.boxplot(arr)\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "plt.show()\n",
        "#HISTOGRAM.\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(windows)\n",
        "plt.show()\n",
        "\n",
        "###############################################################################################\n",
        "#Finding the ouliers \n",
        "# finding the 1st quartile\n",
        "q1 = np.quantile(windows, 0.25)\n",
        " \n",
        "# finding the 3rd quartile\n",
        "q3 = np.quantile(windows, 0.75)\n",
        "med = np.median(windows)\n",
        " \n",
        "# finding the iqr region\n",
        "iqr = q3-q1\n",
        " \n",
        "# finding upper and lower whiskers\n",
        "upper_bound = q3+(1.5*iqr)\n",
        "lower_bound = q1-(1.5*iqr)\n",
        "print(\"IQR, upper bound and lower bound values are :\")\n",
        "print(iqr, upper_bound, lower_bound)\n",
        "\n",
        "###############################################################################################\n",
        "\n",
        "#Removing and saving the list of dataframes for each stride.\n",
        "list_of_df = []\n",
        "windowsRemoved = []\n",
        "for each in range(0, (len(peaks) - 1), 1  ):\n",
        "  if 54 <= abs(peaks[each + 1]- peaks[each]) <= 106:\n",
        "    list_of_df.append( df.loc[ peaks[each]:(peaks[each  + 1] - 1 ) ] )           \n",
        "  else: \n",
        "    windowsRemoved.append((peaks[each + 1]- peaks[each]))\n",
        "################################################################################################\n",
        "#zero imputing for each stride.\n",
        "list_of_Zerodf = []\n",
        "for each in range(0, len(list_of_df) ,1 ):\n",
        "  i = np.arange(start= list_of_df[each].shape[0] + 1 , stop=111 )\n",
        "  df_zero = pd.DataFrame(0, index=i, columns=list_of_df[each].columns)\n",
        "  w1 = pd.concat([list_of_df[each],df_zero])  \n",
        "  list_of_Zerodf.append(w1) \n",
        "\n",
        "print(list_of_Zerodf[4])\n",
        "\n",
        "#dataset after combining zero imputed df's.\n",
        "FinalDataFrame = pd.concat(list_of_Zerodf)\n",
        "\n",
        "xs = []\n",
        "ys = []\n",
        "zs = []\n",
        "test_labels = []\n",
        "new_list = []\n",
        "window_size = 110\n",
        "step_size = 110\n",
        "\n",
        "for i in range(0, FinalDataFrame.shape[0] - window_size, step_size):\n",
        "  xs = FinalDataFrame['x'].values[i: i + 110]\n",
        "  ys = FinalDataFrame['y'].values[i: i + 110]\n",
        "  zs = FinalDataFrame['z'].values[i: i + 110]\n",
        "\n",
        "  label = FinalDataFrame['label'].values[i: i + 110][0] \n",
        "  a = np.c_[ xs,ys,zs ]\n",
        "  new_list.append(a)\n",
        "  test_labels.append(label)\n",
        "\n",
        "test_x = np.asarray(new_list)\n",
        "test_y = np.asarray(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "wZBT_IWX90g3",
        "outputId": "48cbc20f-dca1-4336-83b1-d5ff708003f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Unnamed: 0  subj_id      loc_id  time_s  ...      y      z  magnitude  label\n",
            "432         432       15  left_wrist    4.32  ... -0.961 -0.250   0.995450      0\n",
            "433         433       15  left_wrist    4.33  ... -0.914 -0.238   0.948757      0\n",
            "434         434       15  left_wrist    4.34  ... -0.875 -0.207   0.906225      0\n",
            "435         435       15  left_wrist    4.35  ... -0.848 -0.184   0.881644      0\n",
            "436         436       15  left_wrist    4.36  ... -0.844 -0.168   0.881499      0\n",
            "..          ...      ...         ...     ...  ...    ...    ...        ...    ...\n",
            "106           0        0           0    0.00  ...  0.000  0.000   0.000000      0\n",
            "107           0        0           0    0.00  ...  0.000  0.000   0.000000      0\n",
            "108           0        0           0    0.00  ...  0.000  0.000   0.000000      0\n",
            "109           0        0           0    0.00  ...  0.000  0.000   0.000000      0\n",
            "110           0        0           0    0.00  ...  0.000  0.000   0.000000      0\n",
            "\n",
            "[110 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CNN***"
      ],
      "metadata": {
        "id": "DMRrwcXsEGyG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVTwOH0AWzvW",
        "outputId": "43761f22-00ae-4ae4-c41a-f36fe04ebee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 109, 160)          1120      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 109, 160)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 108, 128)          41088     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 108, 128)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 107, 96)           24672     \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 106, 64)           12352     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 106, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6784)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 6784)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                434240    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 513,537\n",
            "Trainable params: 513,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_cnn = Sequential() \n",
        "\n",
        "model_cnn.add(Conv1D(filters=160, kernel_size=2, activation='relu', input_shape=(110,3)))\n",
        "\n",
        "model_cnn.add(MaxPooling1D(pool_size=1))\n",
        "model_cnn.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
        "model_cnn.add(MaxPooling1D(pool_size=1))\n",
        "model_cnn.add(Conv1D(filters=96, kernel_size=2, activation='relu'))\n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
        "model_cnn.add(MaxPooling1D(pool_size=1))\n",
        "model_cnn.add(Flatten()) \n",
        "model_cnn.add(Dropout(0.5))\n",
        "model_cnn.add(Dense(64, activation='sigmoid'))\n",
        "model_cnn.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model_cnn.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "model_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy4JzqI-W0kg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8d51eb-dea4-438d-c554-147d660ff135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 3s 60ms/step - loss: 0.6973 - accuracy: 0.5004 - recall: 0.6225 - precision: 0.5070\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6928 - accuracy: 0.5156 - recall: 0.7865 - precision: 0.5154\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6922 - accuracy: 0.5133 - recall: 0.9076 - precision: 0.5120\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6917 - accuracy: 0.5204 - recall: 0.8210 - precision: 0.5179\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6902 - accuracy: 0.5238 - recall: 0.8055 - precision: 0.5204\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6911 - accuracy: 0.5233 - recall: 0.5713 - precision: 0.5288\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6912 - accuracy: 0.5153 - recall: 0.3176 - precision: 0.5396\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6909 - accuracy: 0.5105 - recall: 0.2548 - precision: 0.5392\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6922 - accuracy: 0.5131 - recall: 0.1795 - precision: 0.5667\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6933 - accuracy: 0.5069 - recall: 0.6164 - precision: 0.5125\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6891 - accuracy: 0.5263 - recall: 0.5254 - precision: 0.5347\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6896 - accuracy: 0.5286 - recall: 0.7889 - precision: 0.5242\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6896 - accuracy: 0.5154 - recall: 0.2074 - precision: 0.5636\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6884 - accuracy: 0.5259 - recall: 0.7303 - precision: 0.5242\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6899 - accuracy: 0.5211 - recall: 0.3858 - precision: 0.5406\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6875 - accuracy: 0.5367 - recall: 0.7101 - precision: 0.5333\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6868 - accuracy: 0.5344 - recall: 0.6284 - precision: 0.5358\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6864 - accuracy: 0.5354 - recall: 0.4674 - precision: 0.5507\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6866 - accuracy: 0.5468 - recall: 0.5957 - precision: 0.5501\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6837 - accuracy: 0.5483 - recall: 0.5890 - precision: 0.5523\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6844 - accuracy: 0.5358 - recall: 0.6680 - precision: 0.5348\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6836 - accuracy: 0.5421 - recall: 0.6251 - precision: 0.5431\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6834 - accuracy: 0.5389 - recall: 0.4920 - precision: 0.5522\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6834 - accuracy: 0.5427 - recall: 0.6232 - precision: 0.5438\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6848 - accuracy: 0.5470 - recall: 0.6315 - precision: 0.5472\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6823 - accuracy: 0.5532 - recall: 0.6447 - precision: 0.5518\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6821 - accuracy: 0.5441 - recall: 0.6169 - precision: 0.5457\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6841 - accuracy: 0.5461 - recall: 0.4195 - precision: 0.5732\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6807 - accuracy: 0.5548 - recall: 0.6680 - precision: 0.5512\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6856 - accuracy: 0.5400 - recall: 0.3435 - precision: 0.5804\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6810 - accuracy: 0.5575 - recall: 0.5927 - precision: 0.5614\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6826 - accuracy: 0.5505 - recall: 0.7164 - precision: 0.5440\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6813 - accuracy: 0.5461 - recall: 0.5064 - precision: 0.5592\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6800 - accuracy: 0.5527 - recall: 0.6927 - precision: 0.5474\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6794 - accuracy: 0.5595 - recall: 0.5903 - precision: 0.5638\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6792 - accuracy: 0.5626 - recall: 0.6541 - precision: 0.5597\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6808 - accuracy: 0.5550 - recall: 0.5112 - precision: 0.5694\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6782 - accuracy: 0.5642 - recall: 0.5360 - precision: 0.5768\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6784 - accuracy: 0.5634 - recall: 0.5313 - precision: 0.5766\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6789 - accuracy: 0.5604 - recall: 0.6626 - precision: 0.5568\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6808 - accuracy: 0.5593 - recall: 0.4112 - precision: 0.5965\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6788 - accuracy: 0.5530 - recall: 0.6487 - precision: 0.5513\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6813 - accuracy: 0.5589 - recall: 0.4269 - precision: 0.5916\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6785 - accuracy: 0.5542 - recall: 0.5461 - precision: 0.5635\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6762 - accuracy: 0.5618 - recall: 0.6086 - precision: 0.5640\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6756 - accuracy: 0.5623 - recall: 0.5668 - precision: 0.5699\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6755 - accuracy: 0.5625 - recall: 0.5550 - precision: 0.5718\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6751 - accuracy: 0.5669 - recall: 0.6432 - precision: 0.5651\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6742 - accuracy: 0.5744 - recall: 0.5239 - precision: 0.5919\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6753 - accuracy: 0.5661 - recall: 0.6410 - precision: 0.5644\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6770 - accuracy: 0.5637 - recall: 0.4378 - precision: 0.5966\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6766 - accuracy: 0.5554 - recall: 0.6295 - precision: 0.5553\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6763 - accuracy: 0.5593 - recall: 0.4417 - precision: 0.5887\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6728 - accuracy: 0.5668 - recall: 0.6345 - precision: 0.5660\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6762 - accuracy: 0.5737 - recall: 0.4433 - precision: 0.6113\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6779 - accuracy: 0.5644 - recall: 0.7340 - precision: 0.5540\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6730 - accuracy: 0.5695 - recall: 0.6073 - precision: 0.5721\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6720 - accuracy: 0.5754 - recall: 0.5537 - precision: 0.5873\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6713 - accuracy: 0.5709 - recall: 0.6463 - precision: 0.5686\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6719 - accuracy: 0.5710 - recall: 0.5914 - precision: 0.5761\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6722 - accuracy: 0.5727 - recall: 0.5635 - precision: 0.5824\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6736 - accuracy: 0.5690 - recall: 0.5452 - precision: 0.5811\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6687 - accuracy: 0.5804 - recall: 0.6423 - precision: 0.5787\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6723 - accuracy: 0.5735 - recall: 0.6286 - precision: 0.5734\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6718 - accuracy: 0.5709 - recall: 0.6160 - precision: 0.5725\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6713 - accuracy: 0.5689 - recall: 0.6254 - precision: 0.5692\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6677 - accuracy: 0.5853 - recall: 0.5855 - precision: 0.5934\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6708 - accuracy: 0.5792 - recall: 0.6145 - precision: 0.5815\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6681 - accuracy: 0.5740 - recall: 0.5744 - precision: 0.5821\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6680 - accuracy: 0.5781 - recall: 0.6304 - precision: 0.5780\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6686 - accuracy: 0.5773 - recall: 0.5679 - precision: 0.5872\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6730 - accuracy: 0.5713 - recall: 0.5672 - precision: 0.5801\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6686 - accuracy: 0.5767 - recall: 0.6382 - precision: 0.5754\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6706 - accuracy: 0.5713 - recall: 0.3938 - precision: 0.6241\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6687 - accuracy: 0.5800 - recall: 0.6985 - precision: 0.5710\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6670 - accuracy: 0.5775 - recall: 0.5800 - precision: 0.5851\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6662 - accuracy: 0.5792 - recall: 0.6336 - precision: 0.5787\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6656 - accuracy: 0.5868 - recall: 0.6502 - precision: 0.5840\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6644 - accuracy: 0.5873 - recall: 0.5844 - precision: 0.5960\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6637 - accuracy: 0.5817 - recall: 0.5369 - precision: 0.5987\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6635 - accuracy: 0.5873 - recall: 0.5101 - precision: 0.6131\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6615 - accuracy: 0.5933 - recall: 0.6306 - precision: 0.5942\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6618 - accuracy: 0.5876 - recall: 0.5578 - precision: 0.6019\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6637 - accuracy: 0.5853 - recall: 0.5785 - precision: 0.5947\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6644 - accuracy: 0.5849 - recall: 0.5347 - precision: 0.6035\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6638 - accuracy: 0.5889 - recall: 0.6208 - precision: 0.5910\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6603 - accuracy: 0.5893 - recall: 0.5997 - precision: 0.5954\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6637 - accuracy: 0.5813 - recall: 0.5881 - precision: 0.5882\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6604 - accuracy: 0.5945 - recall: 0.5981 - precision: 0.6018\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6628 - accuracy: 0.5924 - recall: 0.6362 - precision: 0.5923\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6618 - accuracy: 0.5945 - recall: 0.5702 - precision: 0.6078\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6594 - accuracy: 0.5928 - recall: 0.6471 - precision: 0.5909\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6621 - accuracy: 0.5895 - recall: 0.5023 - precision: 0.6186\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6616 - accuracy: 0.5933 - recall: 0.6515 - precision: 0.5906\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6596 - accuracy: 0.5924 - recall: 0.6140 - precision: 0.5962\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6583 - accuracy: 0.5935 - recall: 0.5310 - precision: 0.6163\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6635 - accuracy: 0.5854 - recall: 0.6201 - precision: 0.5874\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6599 - accuracy: 0.5927 - recall: 0.6162 - precision: 0.5962\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6602 - accuracy: 0.5932 - recall: 0.5916 - precision: 0.6016\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6586 - accuracy: 0.5966 - recall: 0.5875 - precision: 0.6066\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1e81e6e050>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model_cnn.fit(train_x, train_y, epochs=100, batch_size=1000, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***EVALUATION***"
      ],
      "metadata": {
        "id": "RrPI7z9xFCTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model_cnn.evaluate(test_x,test_y, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRwJhoyF_UgB",
        "outputId": "7566ad3c-4293-4446-90bc-995877995486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87/87 [==============================] - 1s 4ms/step - loss: 0.7503 - accuracy: 0.5050 - recall: 0.4345 - precision: 0.5122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model_cnn.predict(test_x) \n",
        "pred = np.argmax(pred, axis = 1)\n",
        "label = test_y\n",
        "\n",
        "x = pd.DataFrame(pred,columns= [\"preds\"])"
      ],
      "metadata": {
        "id": "Rb_Y-uHo_cPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_y, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSd3zX18_m7v",
        "outputId": "0e4374cc-c1b7-4041-eae1-b1098fe0e70c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1374,    0],\n",
              "       [1404,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "from sklearn.metrics import classification_report\n",
        "print(\"\\n -------------Classification Report-------------\\n\")\n",
        "print(classification_report(test_y, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERyQnVts_qHa",
        "outputId": "d1a47964-6001-4c53-fe6f-3db3bf84da17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " -------------Classification Report-------------\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      1.00      0.66      1374\n",
            "           1       0.00      0.00      0.00      1404\n",
            "\n",
            "    accuracy                           0.49      2778\n",
            "   macro avg       0.25      0.50      0.33      2778\n",
            "weighted avg       0.24      0.49      0.33      2778\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***EXP2***"
      ],
      "metadata": {
        "id": "Cwxs280YNq1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn1 = Sequential() \n",
        "\n",
        "model_cnn1.add(Conv1D(filters=160, kernel_size=2, activation='relu', input_shape=(110,3)))\n",
        "\n",
        "model_cnn1.add(MaxPooling1D(pool_size=1))\n",
        "model_cnn1.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
        "model_cnn1.add(MaxPooling1D(pool_size=1))\n",
        "# model_cnn1.add(Conv1D(filters=96, kernel_size=2, activation='relu'))\n",
        "# model_cnn1.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
        "model_cnn1.add(MaxPooling1D(pool_size=1))\n",
        "model_cnn1.add(Flatten())\n",
        "model_cnn1.add(Dropout(0.5))\n",
        "# model_cnn1.add(Dense(64, activation='sigmoid'))\n",
        "model_cnn1.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model_cnn1.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "model_cnn1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UZCB0OiNldI",
        "outputId": "e66e0744-85f2-41d9-9ecb-fcd939cd8db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_6 (Conv1D)           (None, 109, 160)          1120      \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPooling  (None, 109, 160)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 108, 128)          41088     \n",
            "                                                                 \n",
            " max_pooling1d_7 (MaxPooling  (None, 108, 128)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " max_pooling1d_8 (MaxPooling  (None, 108, 128)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 13824)             0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 13824)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 13825     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56,033\n",
            "Trainable params: 56,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn1.fit(train_x, train_y, epochs=100, batch_size=1000, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNnKkppaN-7c",
        "outputId": "129bc888-81b1-4ee6-cac9-c874a2565f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 21ms/step - loss: 0.6963 - accuracy: 0.5040 - recall_2: 0.6419 - precision_2: 0.5097\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6938 - accuracy: 0.5130 - recall_2: 0.6201 - precision_2: 0.5175\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6930 - accuracy: 0.5038 - recall_2: 0.5149 - precision_2: 0.5119\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6906 - accuracy: 0.5185 - recall_2: 0.6214 - precision_2: 0.5222\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6894 - accuracy: 0.5314 - recall_2: 0.7199 - precision_2: 0.5287\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6894 - accuracy: 0.5313 - recall_2: 0.5763 - precision_2: 0.5363\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6888 - accuracy: 0.5271 - recall_2: 0.7025 - precision_2: 0.5261\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6893 - accuracy: 0.5273 - recall_2: 0.4618 - precision_2: 0.5411\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6875 - accuracy: 0.5358 - recall_2: 0.5698 - precision_2: 0.5413\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6867 - accuracy: 0.5376 - recall_2: 0.5530 - precision_2: 0.5445\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6887 - accuracy: 0.5359 - recall_2: 0.7813 - precision_2: 0.5295\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6862 - accuracy: 0.5439 - recall_2: 0.5515 - precision_2: 0.5514\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6864 - accuracy: 0.5383 - recall_2: 0.7242 - precision_2: 0.5338\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6867 - accuracy: 0.5386 - recall_2: 0.5951 - precision_2: 0.5421\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6911 - accuracy: 0.5331 - recall_2: 0.5519 - precision_2: 0.5398\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6892 - accuracy: 0.5397 - recall_2: 0.5271 - precision_2: 0.5493\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6848 - accuracy: 0.5514 - recall_2: 0.6796 - precision_2: 0.5474\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6848 - accuracy: 0.5420 - recall_2: 0.5328 - precision_2: 0.5513\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6851 - accuracy: 0.5400 - recall_2: 0.8090 - precision_2: 0.5313\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6837 - accuracy: 0.5445 - recall_2: 0.5990 - precision_2: 0.5475\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6833 - accuracy: 0.5500 - recall_2: 0.6676 - precision_2: 0.5470\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6836 - accuracy: 0.5459 - recall_2: 0.6741 - precision_2: 0.5430\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6842 - accuracy: 0.5399 - recall_2: 0.6711 - precision_2: 0.5381\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6832 - accuracy: 0.5481 - recall_2: 0.4683 - precision_2: 0.5673\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6815 - accuracy: 0.5561 - recall_2: 0.6676 - precision_2: 0.5525\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6829 - accuracy: 0.5515 - recall_2: 0.6127 - precision_2: 0.5532\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6814 - accuracy: 0.5546 - recall_2: 0.6548 - precision_2: 0.5523\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6808 - accuracy: 0.5531 - recall_2: 0.5912 - precision_2: 0.5569\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6839 - accuracy: 0.5414 - recall_2: 0.8196 - precision_2: 0.5317\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6802 - accuracy: 0.5519 - recall_2: 0.5997 - precision_2: 0.5548\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6789 - accuracy: 0.5603 - recall_2: 0.5977 - precision_2: 0.5637\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6811 - accuracy: 0.5559 - recall_2: 0.5803 - precision_2: 0.5611\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6799 - accuracy: 0.5574 - recall_2: 0.6596 - precision_2: 0.5544\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6788 - accuracy: 0.5581 - recall_2: 0.5709 - precision_2: 0.5646\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6785 - accuracy: 0.5603 - recall_2: 0.6578 - precision_2: 0.5572\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6779 - accuracy: 0.5614 - recall_2: 0.6968 - precision_2: 0.5546\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6788 - accuracy: 0.5610 - recall_2: 0.4796 - precision_2: 0.5828\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6787 - accuracy: 0.5601 - recall_2: 0.7669 - precision_2: 0.5481\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6776 - accuracy: 0.5608 - recall_2: 0.6735 - precision_2: 0.5562\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6764 - accuracy: 0.5632 - recall_2: 0.5199 - precision_2: 0.5782\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6780 - accuracy: 0.5585 - recall_2: 0.6484 - precision_2: 0.5564\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6777 - accuracy: 0.5605 - recall_2: 0.5317 - precision_2: 0.5730\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6767 - accuracy: 0.5598 - recall_2: 0.6301 - precision_2: 0.5596\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6753 - accuracy: 0.5678 - recall_2: 0.6162 - precision_2: 0.5692\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6760 - accuracy: 0.5670 - recall_2: 0.6772 - precision_2: 0.5615\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6751 - accuracy: 0.5666 - recall_2: 0.5766 - precision_2: 0.5733\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6764 - accuracy: 0.5620 - recall_2: 0.5979 - precision_2: 0.5654\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6747 - accuracy: 0.5700 - recall_2: 0.5842 - precision_2: 0.5760\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6746 - accuracy: 0.5674 - recall_2: 0.5631 - precision_2: 0.5762\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6740 - accuracy: 0.5685 - recall_2: 0.5975 - precision_2: 0.5724\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6746 - accuracy: 0.5654 - recall_2: 0.6397 - precision_2: 0.5639\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6743 - accuracy: 0.5668 - recall_2: 0.5319 - precision_2: 0.5807\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6755 - accuracy: 0.5632 - recall_2: 0.6251 - precision_2: 0.5634\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6728 - accuracy: 0.5724 - recall_2: 0.6447 - precision_2: 0.5702\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6743 - accuracy: 0.5707 - recall_2: 0.5990 - precision_2: 0.5746\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6731 - accuracy: 0.5732 - recall_2: 0.5661 - precision_2: 0.5826\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6742 - accuracy: 0.5674 - recall_2: 0.6617 - precision_2: 0.5634\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6751 - accuracy: 0.5692 - recall_2: 0.4849 - precision_2: 0.5933\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6722 - accuracy: 0.5723 - recall_2: 0.6118 - precision_2: 0.5744\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6736 - accuracy: 0.5776 - recall_2: 0.5720 - precision_2: 0.5867\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6701 - accuracy: 0.5769 - recall_2: 0.5785 - precision_2: 0.5848\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6732 - accuracy: 0.5729 - recall_2: 0.6099 - precision_2: 0.5754\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6711 - accuracy: 0.5806 - recall_2: 0.5417 - precision_2: 0.5963\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6701 - accuracy: 0.5763 - recall_2: 0.5909 - precision_2: 0.5821\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6715 - accuracy: 0.5777 - recall_2: 0.6776 - precision_2: 0.5713\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6701 - accuracy: 0.5780 - recall_2: 0.5770 - precision_2: 0.5863\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6727 - accuracy: 0.5728 - recall_2: 0.5835 - precision_2: 0.5792\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6719 - accuracy: 0.5744 - recall_2: 0.5101 - precision_2: 0.5949\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6701 - accuracy: 0.5770 - recall_2: 0.6811 - precision_2: 0.5703\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6704 - accuracy: 0.5740 - recall_2: 0.6892 - precision_2: 0.5666\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6690 - accuracy: 0.5798 - recall_2: 0.5546 - precision_2: 0.5926\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6690 - accuracy: 0.5750 - recall_2: 0.6273 - precision_2: 0.5752\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6684 - accuracy: 0.5787 - recall_2: 0.6288 - precision_2: 0.5788\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6674 - accuracy: 0.5843 - recall_2: 0.5607 - precision_2: 0.5971\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6704 - accuracy: 0.5807 - recall_2: 0.6007 - precision_2: 0.5853\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6680 - accuracy: 0.5832 - recall_2: 0.6173 - precision_2: 0.5854\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6663 - accuracy: 0.5881 - recall_2: 0.5881 - precision_2: 0.5962\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6683 - accuracy: 0.5771 - recall_2: 0.5450 - precision_2: 0.5912\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6669 - accuracy: 0.5827 - recall_2: 0.7059 - precision_2: 0.5726\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6676 - accuracy: 0.5807 - recall_2: 0.5676 - precision_2: 0.5912\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6683 - accuracy: 0.5835 - recall_2: 0.5824 - precision_2: 0.5919\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6646 - accuracy: 0.5907 - recall_2: 0.6217 - precision_2: 0.5930\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6690 - accuracy: 0.5787 - recall_2: 0.6842 - precision_2: 0.5715\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6679 - accuracy: 0.5787 - recall_2: 0.6452 - precision_2: 0.5765\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6659 - accuracy: 0.5803 - recall_2: 0.6731 - precision_2: 0.5745\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6668 - accuracy: 0.5829 - recall_2: 0.6611 - precision_2: 0.5785\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6657 - accuracy: 0.5793 - recall_2: 0.6502 - precision_2: 0.5765\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6627 - accuracy: 0.5933 - recall_2: 0.6125 - precision_2: 0.5975\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6644 - accuracy: 0.5905 - recall_2: 0.6225 - precision_2: 0.5926\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6665 - accuracy: 0.5831 - recall_2: 0.6040 - precision_2: 0.5875\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6648 - accuracy: 0.5880 - recall_2: 0.6116 - precision_2: 0.5917\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6621 - accuracy: 0.5889 - recall_2: 0.6452 - precision_2: 0.5870\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6618 - accuracy: 0.5954 - recall_2: 0.5722 - precision_2: 0.6085\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6644 - accuracy: 0.5825 - recall_2: 0.5975 - precision_2: 0.5880\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6646 - accuracy: 0.5923 - recall_2: 0.6382 - precision_2: 0.5918\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6654 - accuracy: 0.5881 - recall_2: 0.5846 - precision_2: 0.5968\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6635 - accuracy: 0.5905 - recall_2: 0.5646 - precision_2: 0.6041\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6635 - accuracy: 0.5930 - recall_2: 0.6147 - precision_2: 0.5967\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6631 - accuracy: 0.5850 - recall_2: 0.6602 - precision_2: 0.5808\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.6613 - accuracy: 0.5915 - recall_2: 0.5748 - precision_2: 0.6031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1e805a4c10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model_cnn.evaluate(test_x,test_y, verbose=1)\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4OORTFtOHaR",
        "outputId": "e7e219df-fe1f-4e5a-f52d-34295f88ebc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87/87 [==============================] - 0s 3ms/step - loss: 0.7503 - accuracy: 0.5050 - recall: 0.4345 - precision: 0.5122\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7503039240837097, 0.5050395727157593, 0.4344729483127594, 0.512174665927887]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model_cnn.predict(test_x) \n",
        "pred = np.argmax(pred, axis = 1)\n",
        "label = test_y\n",
        "\n",
        "x = pd.DataFrame(pred,columns= [\"preds\"])"
      ],
      "metadata": {
        "id": "C5lalOVBR0lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_y, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbKbnfnoR4Ko",
        "outputId": "84cfba58-6b42-4c2a-c55c-30a0d3378754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1374,    0],\n",
              "       [1404,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "from sklearn.metrics import classification_report\n",
        "print(\"\\n -------------Classification Report-------------\\n\")\n",
        "print(classification_report(test_y, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7-yEZgxR9Xn",
        "outputId": "df6388bd-b8ce-4340-9d12-389bc5dd6803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " -------------Classification Report-------------\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      1.00      0.66      1374\n",
            "           1       0.00      0.00      0.00      1404\n",
            "\n",
            "    accuracy                           0.49      2778\n",
            "   macro avg       0.25      0.50      0.33      2778\n",
            "weighted avg       0.24      0.49      0.33      2778\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***EXP 3***"
      ],
      "metadata": {
        "id": "e8webxDA4cmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "x_-wwD5S4XDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn2 = Sequential() \n",
        "\n",
        "model_cnn2.add(Conv1D(filters=160, kernel_size=2, activation='relu', input_shape=(110,3),kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "model_cnn2.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
        "\n",
        "model_cnn2.add(Flatten())\n",
        "model_cnn2.add(Dropout(0.7))\n",
        "\n",
        "model_cnn2.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model_cnn2.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "model_cnn2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaamenLa4ozQ",
        "outputId": "cd82d514-3cba-4fce-caea-729357013197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_8 (Conv1D)           (None, 109, 160)          1120      \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 108, 128)          41088     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 13824)             0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 13824)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 13825     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56,033\n",
            "Trainable params: 56,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn2.fit(train_x, train_y, epochs=50, batch_size=1000, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqTxzNGi5_IK",
        "outputId": "cd065f1c-1f13-4641-9fe5-7aaf252ac7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 1s 16ms/step - loss: 0.7513 - accuracy: 0.4996 - recall_3: 0.6214 - precision_3: 0.5064\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7392 - accuracy: 0.5084 - recall_3: 0.4265 - precision_3: 0.5201\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7306 - accuracy: 0.5154 - recall_3: 0.7519 - precision_3: 0.5161\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7236 - accuracy: 0.5161 - recall_3: 0.6441 - precision_3: 0.5194\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7169 - accuracy: 0.5235 - recall_3: 0.6983 - precision_3: 0.5235\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7127 - accuracy: 0.5252 - recall_3: 0.4372 - precision_3: 0.5408\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7093 - accuracy: 0.5204 - recall_3: 0.7894 - precision_3: 0.5186\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7051 - accuracy: 0.5315 - recall_3: 0.7179 - precision_3: 0.5289\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7030 - accuracy: 0.5293 - recall_3: 0.5591 - precision_3: 0.5355\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7012 - accuracy: 0.5300 - recall_3: 0.5920 - precision_3: 0.5340\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6992 - accuracy: 0.5311 - recall_3: 0.4243 - precision_3: 0.5503\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6974 - accuracy: 0.5292 - recall_3: 0.8022 - precision_3: 0.5241\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6974 - accuracy: 0.5250 - recall_3: 0.6112 - precision_3: 0.5283\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6956 - accuracy: 0.5243 - recall_3: 0.7295 - precision_3: 0.5230\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6949 - accuracy: 0.5278 - recall_3: 0.7356 - precision_3: 0.5254\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6938 - accuracy: 0.5311 - recall_3: 0.8173 - precision_3: 0.5249\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6941 - accuracy: 0.5254 - recall_3: 0.9005 - precision_3: 0.5192\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6929 - accuracy: 0.5238 - recall_3: 0.6940 - precision_3: 0.5238\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6939 - accuracy: 0.5252 - recall_3: 0.6957 - precision_3: 0.5249\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6920 - accuracy: 0.5340 - recall_3: 0.7214 - precision_3: 0.5307\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6920 - accuracy: 0.5292 - recall_3: 0.6175 - precision_3: 0.5318\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6942 - accuracy: 0.5284 - recall_3: 0.8419 - precision_3: 0.5224\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6914 - accuracy: 0.5305 - recall_3: 0.6062 - precision_3: 0.5337\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6920 - accuracy: 0.5339 - recall_3: 0.5683 - precision_3: 0.5395\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6918 - accuracy: 0.5280 - recall_3: 0.6467 - precision_3: 0.5292\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6919 - accuracy: 0.5343 - recall_3: 0.5955 - precision_3: 0.5379\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6916 - accuracy: 0.5303 - recall_3: 0.6275 - precision_3: 0.5322\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6911 - accuracy: 0.5300 - recall_3: 0.5750 - precision_3: 0.5351\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6919 - accuracy: 0.5276 - recall_3: 0.4759 - precision_3: 0.5402\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6903 - accuracy: 0.5342 - recall_3: 0.5472 - precision_3: 0.5414\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6905 - accuracy: 0.5358 - recall_3: 0.4670 - precision_3: 0.5513\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6916 - accuracy: 0.5242 - recall_3: 0.6957 - precision_3: 0.5241\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6906 - accuracy: 0.5272 - recall_3: 0.4777 - precision_3: 0.5395\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6908 - accuracy: 0.5303 - recall_3: 0.6940 - precision_3: 0.5290\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6911 - accuracy: 0.5282 - recall_3: 0.6230 - precision_3: 0.5306\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6915 - accuracy: 0.5204 - recall_3: 0.7417 - precision_3: 0.5198\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6912 - accuracy: 0.5353 - recall_3: 0.4271 - precision_3: 0.5558\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6910 - accuracy: 0.5286 - recall_3: 0.5724 - precision_3: 0.5339\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6906 - accuracy: 0.5353 - recall_3: 0.6232 - precision_3: 0.5370\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6901 - accuracy: 0.5342 - recall_3: 0.6386 - precision_3: 0.5350\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6898 - accuracy: 0.5355 - recall_3: 0.5648 - precision_3: 0.5413\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.6903 - accuracy: 0.5210 - recall_3: 0.6330 - precision_3: 0.5239\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6898 - accuracy: 0.5374 - recall_3: 0.7539 - precision_3: 0.5317\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6898 - accuracy: 0.5332 - recall_3: 0.6596 - precision_3: 0.5330\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6883 - accuracy: 0.5332 - recall_3: 0.6524 - precision_3: 0.5334\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6901 - accuracy: 0.5331 - recall_3: 0.6624 - precision_3: 0.5328\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6900 - accuracy: 0.5364 - recall_3: 0.7066 - precision_3: 0.5332\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6895 - accuracy: 0.5324 - recall_3: 0.6275 - precision_3: 0.5341\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6894 - accuracy: 0.5316 - recall_3: 0.6345 - precision_3: 0.5330\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6903 - accuracy: 0.5291 - recall_3: 0.5230 - precision_3: 0.5379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1e7e093c90>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model_cnn2.evaluate(test_x,test_y, verbose=1)\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOV8VBo55E8X",
        "outputId": "a4b8172a-7f3a-4a29-8971-ff75af641732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87/87 [==============================] - 1s 3ms/step - loss: 0.7134 - accuracy: 0.5047 - recall_3: 0.3903 - precision_3: 0.5131\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7134271264076233,\n",
              " 0.5046796202659607,\n",
              " 0.39031338691711426,\n",
              " 0.5131086111068726]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model_cnn.predict(test_x) \n",
        "pred = np.argmax(pred, axis = 1)\n",
        "label = test_y\n",
        "\n",
        "x = pd.DataFrame(pred,columns= [\"preds\"])"
      ],
      "metadata": {
        "id": "RW_V1hGg5H4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_y, pred)"
      ],
      "metadata": {
        "id": "KU38rfdg5KF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902c70d4-c498-4043-b22d-38f638ca508d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1374,    0],\n",
              "       [1404,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "from sklearn.metrics import classification_report\n",
        "print(\"\\n -------------Classification Report-------------\\n\")\n",
        "print(classification_report(test_y, pred))"
      ],
      "metadata": {
        "id": "Y_VYq0Hc5McJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e1ee4f-5fbb-405f-a9ff-c5773aaa1316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " -------------Classification Report-------------\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      1.00      0.66      1374\n",
            "           1       0.00      0.00      0.00      1404\n",
            "\n",
            "    accuracy                           0.49      2778\n",
            "   macro avg       0.25      0.50      0.33      2778\n",
            "weighted avg       0.24      0.49      0.33      2778\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***EXP4***"
      ],
      "metadata": {
        "id": "lLRhQzCM8Ic0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "model_cnn3 = Sequential() \n",
        "\n",
        "model_cnn3.add(Conv1D(filters=160, kernel_size=2, activation='relu', input_shape=(110,3), kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\n",
        "model_cnn3.add(Conv1D(filters=128, kernel_size=2, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\n",
        "model_cnn3.add(Flatten())\n",
        "model_cnn3.add(Dropout(0.7))\n",
        "\n",
        "model_cnn3.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model_cnn3.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "model_cnn3.summary()\n",
        "\n",
        "#_________\n",
        "model_cnn3.fit(train_x, train_y, epochs=50, batch_size=1000, verbose=1)\n",
        "#________\n",
        "scores = model_cnn3.evaluate(test_x,test_y, verbose=1)\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgXGJSnX8PFJ",
        "outputId": "82421ee0-0c23-4e85-c954-96fefc802939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_10 (Conv1D)          (None, 109, 160)          1120      \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 108, 128)          41088     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 13824)             0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 13824)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 13825     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56,033\n",
            "Trainable params: 56,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 1s 15ms/step - loss: 2.0126 - accuracy: 0.4978 - recall_4: 0.5872 - precision_4: 0.5052\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.6678 - accuracy: 0.5107 - recall_4: 0.9238 - precision_4: 0.5103\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.3977 - accuracy: 0.5198 - recall_4: 0.5530 - precision_4: 0.5263\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1951 - accuracy: 0.5143 - recall_4: 0.4404 - precision_4: 0.5267\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0450 - accuracy: 0.5162 - recall_4: 0.7929 - precision_4: 0.5157\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9369 - accuracy: 0.5182 - recall_4: 0.8534 - precision_4: 0.5158\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8599 - accuracy: 0.5142 - recall_4: 0.8541 - precision_4: 0.5134\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8062 - accuracy: 0.5171 - recall_4: 0.7820 - precision_4: 0.5165\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7705 - accuracy: 0.5046 - recall_4: 0.4128 - precision_4: 0.5159\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7435 - accuracy: 0.5182 - recall_4: 0.8715 - precision_4: 0.5155\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7264 - accuracy: 0.5173 - recall_4: 0.9063 - precision_4: 0.5143\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7149 - accuracy: 0.5150 - recall_4: 0.9137 - precision_4: 0.5129\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7074 - accuracy: 0.5127 - recall_4: 0.5877 - precision_4: 0.5182\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7030 - accuracy: 0.5078 - recall_4: 0.3080 - precision_4: 0.5272\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6997 - accuracy: 0.5102 - recall_4: 0.9026 - precision_4: 0.5103\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6976 - accuracy: 0.5079 - recall_4: 0.6497 - precision_4: 0.5126\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.6961 - accuracy: 0.5132 - recall_4: 0.7656 - precision_4: 0.5143\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6950 - accuracy: 0.5159 - recall_4: 0.9255 - precision_4: 0.5132\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6945 - accuracy: 0.5174 - recall_4: 0.8636 - precision_4: 0.5151\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6943 - accuracy: 0.5104 - recall_4: 0.8795 - precision_4: 0.5107\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6938 - accuracy: 0.5181 - recall_4: 0.7992 - precision_4: 0.5168\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6937 - accuracy: 0.5145 - recall_4: 0.6755 - precision_4: 0.5172\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6935 - accuracy: 0.5142 - recall_4: 0.9005 - precision_4: 0.5126\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6940 - accuracy: 0.5097 - recall_4: 0.9869 - precision_4: 0.5092\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6935 - accuracy: 0.5102 - recall_4: 0.9577 - precision_4: 0.5097\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6934 - accuracy: 0.5158 - recall_4: 0.8850 - precision_4: 0.5138\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6936 - accuracy: 0.5076 - recall_4: 0.5557 - precision_4: 0.5145\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5242 - recall_4: 0.7635 - precision_4: 0.5219\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5136 - recall_4: 0.7523 - precision_4: 0.5148\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6936 - accuracy: 0.5118 - recall_4: 0.9582 - precision_4: 0.5106\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6936 - accuracy: 0.5131 - recall_4: 0.9547 - precision_4: 0.5113\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6937 - accuracy: 0.5119 - recall_4: 0.9710 - precision_4: 0.5105\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6934 - accuracy: 0.5119 - recall_4: 0.9699 - precision_4: 0.5105\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5123 - recall_4: 0.6079 - precision_4: 0.5173\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.6934 - accuracy: 0.5048 - recall_4: 0.1832 - precision_4: 0.5381\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5102 - recall_4: 0.3132 - precision_4: 0.5310\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5109 - recall_4: 0.9146 - precision_4: 0.5106\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5084 - recall_4: 0.9991 - precision_4: 0.5084\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5091 - recall_4: 0.9662 - precision_4: 0.5091\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5181 - recall_4: 0.7351 - precision_4: 0.5184\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5110 - recall_4: 0.8388 - precision_4: 0.5116\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5110 - recall_4: 0.9630 - precision_4: 0.5101\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5111 - recall_4: 0.8711 - precision_4: 0.5113\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5107 - recall_4: 0.8957 - precision_4: 0.5107\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5119 - recall_4: 0.9599 - precision_4: 0.5106\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5086 - recall_4: 0.9959 - precision_4: 0.5085\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5094 - recall_4: 0.9972 - precision_4: 0.5089\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5099 - recall_4: 0.9802 - precision_4: 0.5093\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5088 - recall_4: 0.9673 - precision_4: 0.5089\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5102 - recall_4: 0.9887 - precision_4: 0.5094\n",
            "87/87 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5054 - recall_4: 1.0000 - precision_4: 0.5054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6932255029678345, 0.5053995847702026, 1.0, 0.5053995847702026]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***EXP5***"
      ],
      "metadata": {
        "id": "FSfTzBIn93LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "rlrop = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=100)\n",
        "\n",
        "model_cnn4 = Sequential() \n",
        "model_cnn4.add(Conv1D(filters=160, kernel_size=2, activation='relu', input_shape=(110,3), kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model_cnn4.add(Conv1D(filters=128, kernel_size=2, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model_cnn4.add(Flatten())\n",
        "model_cnn4.add(Dropout(0.7))\n",
        "model_cnn4.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "\n",
        "model_cnn4.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "model_cnn4.summary()\n",
        "\n",
        "#_________\n",
        "model_cnn4.fit(train_x, train_y, epochs=50, batch_size=1000, verbose=1,callbacks=[rlrop])\n",
        "#________\n",
        "scores = model_cnn4.evaluate(test_x,test_y, verbose=1)\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9_eRiFm92KG",
        "outputId": "4c8a06f8-ffbd-47f0-8fee-efc8eab6514d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_12 (Conv1D)          (None, 109, 160)          1120      \n",
            "                                                                 \n",
            " conv1d_13 (Conv1D)          (None, 108, 128)          41088     \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 13824)             0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 13824)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 13825     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56,033\n",
            "Trainable params: 56,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 1s 15ms/step - loss: 2.0135 - accuracy: 0.5102 - recall_5: 0.5885 - precision_5: 0.5160 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.6660 - accuracy: 0.5119 - recall_5: 0.6415 - precision_5: 0.5160 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.3998 - accuracy: 0.5070 - recall_5: 0.4801 - precision_5: 0.5163 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1977 - accuracy: 0.5135 - recall_5: 0.8676 - precision_5: 0.5127 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0485 - accuracy: 0.5073 - recall_5: 0.4032 - precision_5: 0.5198 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9393 - accuracy: 0.5157 - recall_5: 0.4226 - precision_5: 0.5296 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8619 - accuracy: 0.5157 - recall_5: 0.4829 - precision_5: 0.5257 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8073 - accuracy: 0.5138 - recall_5: 0.7994 - precision_5: 0.5140 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7696 - accuracy: 0.5171 - recall_5: 0.8896 - precision_5: 0.5145 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7436 - accuracy: 0.5189 - recall_5: 0.8255 - precision_5: 0.5168 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.7267 - accuracy: 0.5172 - recall_5: 0.8586 - precision_5: 0.5151 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7149 - accuracy: 0.5172 - recall_5: 0.7948 - precision_5: 0.5163 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7077 - accuracy: 0.5203 - recall_5: 0.6670 - precision_5: 0.5221 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7030 - accuracy: 0.5205 - recall_5: 0.7436 - precision_5: 0.5199 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6998 - accuracy: 0.5146 - recall_5: 0.9183 - precision_5: 0.5126 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6977 - accuracy: 0.5116 - recall_5: 0.9423 - precision_5: 0.5106 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6961 - accuracy: 0.5170 - recall_5: 0.9118 - precision_5: 0.5141 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6953 - accuracy: 0.5170 - recall_5: 0.7205 - precision_5: 0.5179 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6946 - accuracy: 0.5115 - recall_5: 0.9242 - precision_5: 0.5108 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6941 - accuracy: 0.5094 - recall_5: 0.9726 - precision_5: 0.5091 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6939 - accuracy: 0.5104 - recall_5: 0.9072 - precision_5: 0.5104 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6938 - accuracy: 0.5139 - recall_5: 0.9658 - precision_5: 0.5116 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6937 - accuracy: 0.5129 - recall_5: 0.9523 - precision_5: 0.5112 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6935 - accuracy: 0.5171 - recall_5: 0.9229 - precision_5: 0.5139 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5140 - recall_5: 0.8680 - precision_5: 0.5130 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5117 - recall_5: 0.6765 - precision_5: 0.5150 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6935 - accuracy: 0.5118 - recall_5: 0.7510 - precision_5: 0.5136 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5162 - recall_5: 0.9320 - precision_5: 0.5133 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6934 - accuracy: 0.5104 - recall_5: 0.9212 - precision_5: 0.5102 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5133 - recall_5: 0.8003 - precision_5: 0.5137 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5132 - recall_5: 0.7894 - precision_5: 0.5138 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6936 - accuracy: 0.5011 - recall_5: 0.4559 - precision_5: 0.5104 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6939 - accuracy: 0.5122 - recall_5: 0.9473 - precision_5: 0.5109 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5110 - recall_5: 0.9503 - precision_5: 0.5102 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.6933 - accuracy: 0.5092 - recall_5: 0.9606 - precision_5: 0.5092 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5084 - recall_5: 1.0000 - precision_5: 0.5084 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5086 - recall_5: 0.9623 - precision_5: 0.5088 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5045 - recall_5: 0.4014 - precision_5: 0.5162 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5007 - recall_5: 0.3871 - precision_5: 0.5118 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5096 - recall_5: 0.8506 - precision_5: 0.5106 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5096 - recall_5: 0.9726 - precision_5: 0.5092 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5034 - recall_5: 0.9408 - precision_5: 0.5062 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5069 - recall_5: 0.8931 - precision_5: 0.5086 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5004 - recall_5: 0.7935 - precision_5: 0.5055 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.4964 - recall_5: 0.3400 - precision_5: 0.5070 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6934 - accuracy: 0.4915 - recall_5: 0.0233 - precision_5: 0.4977 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5026 - recall_5: 0.3888 - precision_5: 0.5143 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5121 - recall_5: 0.9732 - precision_5: 0.5106 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5081 - recall_5: 0.9989 - precision_5: 0.5083 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5085 - recall_5: 1.0000 - precision_5: 0.5084 - lr: 0.0010\n",
            "87/87 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5054 - recall_5: 1.0000 - precision_5: 0.5054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6931127309799194, 0.5053995847702026, 1.0, 0.5053995847702026]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***EXP7***"
      ],
      "metadata": {
        "id": "R2Wxpn4d_p3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "# import noise layer\n",
        "from keras.layers import GaussianNoise\n",
        "# define noise layer\n",
        "layer = GaussianNoise(0.1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_cnn6 = Sequential() \n",
        "model_cnn6.add(Conv1D(filters=160, kernel_size=2, activation='relu', input_shape=(110,3) , kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model_cnn6.add(GaussianNoise(0.1))\n",
        "model_cnn6.add(Conv1D(filters=128, kernel_size=2, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model_cnn6.add(GaussianNoise(0.1))\n",
        "model_cnn6.add(Flatten())\n",
        "model_cnn6.add(Dropout(0.7))\n",
        "model_cnn6.add(GaussianNoise(0.1))\n",
        "model_cnn6.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "\n",
        "\n",
        "model_cnn6.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "model_cnn6.summary()\n",
        "\n",
        "#_________\n",
        "model_cnn6.fit(train_x, train_y, epochs=50, batch_size=1000, verbose=1, validation_split=0.2)\n",
        "#________\n",
        "scores = model_cnn6.evaluate(test_x,test_y, verbose=1)\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hwycoDh_o7s",
        "outputId": "7ef004bd-f0d1-4023-fc33-31fe410f3304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_14 (Conv1D)          (None, 109, 160)          1120      \n",
            "                                                                 \n",
            " gaussian_noise_1 (GaussianN  (None, 109, 160)         0         \n",
            " oise)                                                           \n",
            "                                                                 \n",
            " conv1d_15 (Conv1D)          (None, 108, 128)          41088     \n",
            "                                                                 \n",
            " gaussian_noise_2 (GaussianN  (None, 108, 128)         0         \n",
            " oise)                                                           \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 13824)             0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 13824)             0         \n",
            "                                                                 \n",
            " gaussian_noise_3 (GaussianN  (None, 13824)            0         \n",
            " oise)                                                           \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 13825     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56,033\n",
            "Trainable params: 56,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 2.0721 - accuracy: 0.4981 - recall_6: 0.5247 - precision_6: 0.5098 - val_loss: 1.8742 - val_accuracy: 0.5053 - val_recall_6: 0.6820 - val_precision_6: 0.4984\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.7859 - accuracy: 0.5080 - recall_6: 0.5534 - precision_6: 0.5186 - val_loss: 1.6210 - val_accuracy: 0.4920 - val_recall_6: 0.9989 - val_precision_6: 0.4922\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.5478 - accuracy: 0.5091 - recall_6: 0.6655 - precision_6: 0.5162 - val_loss: 1.4103 - val_accuracy: 0.5147 - val_recall_6: 0.7034 - val_precision_6: 0.5052\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.3550 - accuracy: 0.5061 - recall_6: 0.4847 - precision_6: 0.5192 - val_loss: 1.2420 - val_accuracy: 0.5246 - val_recall_6: 0.6236 - val_precision_6: 0.5144\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1975 - accuracy: 0.5093 - recall_6: 0.5612 - precision_6: 0.5195 - val_loss: 1.1097 - val_accuracy: 0.4997 - val_recall_6: 0.9876 - val_precision_6: 0.4960\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.0756 - accuracy: 0.5107 - recall_6: 0.5942 - precision_6: 0.5196 - val_loss: 1.0060 - val_accuracy: 0.5097 - val_recall_6: 0.8225 - val_precision_6: 0.5014\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9863 - accuracy: 0.5011 - recall_6: 0.5369 - precision_6: 0.5125 - val_loss: 0.9264 - val_accuracy: 0.5030 - val_recall_6: 0.7371 - val_precision_6: 0.4970\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9128 - accuracy: 0.4999 - recall_6: 0.5566 - precision_6: 0.5109 - val_loss: 0.8661 - val_accuracy: 0.5047 - val_recall_6: 0.8416 - val_precision_6: 0.4983\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8587 - accuracy: 0.5039 - recall_6: 0.5750 - precision_6: 0.5141 - val_loss: 0.8203 - val_accuracy: 0.5014 - val_recall_6: 0.8090 - val_precision_6: 0.4962\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8163 - accuracy: 0.5015 - recall_6: 0.5485 - precision_6: 0.5126 - val_loss: 0.7859 - val_accuracy: 0.5014 - val_recall_6: 0.7910 - val_precision_6: 0.4961\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7884 - accuracy: 0.4949 - recall_6: 0.5471 - precision_6: 0.5065 - val_loss: 0.7606 - val_accuracy: 0.5003 - val_recall_6: 0.7809 - val_precision_6: 0.4954\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7622 - accuracy: 0.5065 - recall_6: 0.5469 - precision_6: 0.5174 - val_loss: 0.7420 - val_accuracy: 0.5030 - val_recall_6: 0.8517 - val_precision_6: 0.4974\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7522 - accuracy: 0.4917 - recall_6: 0.5534 - precision_6: 0.5036 - val_loss: 0.7286 - val_accuracy: 0.4958 - val_recall_6: 0.9978 - val_precision_6: 0.4942\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7367 - accuracy: 0.5011 - recall_6: 0.5847 - precision_6: 0.5115 - val_loss: 0.7193 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7318 - accuracy: 0.4895 - recall_6: 0.5688 - precision_6: 0.5015 - val_loss: 0.7123 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7243 - accuracy: 0.4950 - recall_6: 0.5688 - precision_6: 0.5064 - val_loss: 0.7071 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7142 - accuracy: 0.5087 - recall_6: 0.5747 - precision_6: 0.5185 - val_loss: 0.7035 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7125 - accuracy: 0.5053 - recall_6: 0.5593 - precision_6: 0.5158 - val_loss: 0.7011 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7076 - accuracy: 0.5145 - recall_6: 0.5739 - precision_6: 0.5239 - val_loss: 0.6993 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7101 - accuracy: 0.5022 - recall_6: 0.5612 - precision_6: 0.5130 - val_loss: 0.6980 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7069 - accuracy: 0.5097 - recall_6: 0.5655 - precision_6: 0.5197 - val_loss: 0.6971 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7096 - accuracy: 0.5032 - recall_6: 0.5607 - precision_6: 0.5139 - val_loss: 0.6965 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7062 - accuracy: 0.5091 - recall_6: 0.5717 - precision_6: 0.5190 - val_loss: 0.6964 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7073 - accuracy: 0.5008 - recall_6: 0.5690 - precision_6: 0.5115 - val_loss: 0.6961 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7046 - accuracy: 0.5051 - recall_6: 0.5661 - precision_6: 0.5155 - val_loss: 0.6957 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7075 - accuracy: 0.5030 - recall_6: 0.5496 - precision_6: 0.5140 - val_loss: 0.6956 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7060 - accuracy: 0.5019 - recall_6: 0.5626 - precision_6: 0.5127 - val_loss: 0.6955 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7084 - accuracy: 0.4972 - recall_6: 0.5528 - precision_6: 0.5086 - val_loss: 0.6953 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7067 - accuracy: 0.5003 - recall_6: 0.5507 - precision_6: 0.5114 - val_loss: 0.6953 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7119 - accuracy: 0.4881 - recall_6: 0.5401 - precision_6: 0.5004 - val_loss: 0.6952 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7068 - accuracy: 0.4988 - recall_6: 0.5536 - precision_6: 0.5100 - val_loss: 0.6951 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7092 - accuracy: 0.4999 - recall_6: 0.5488 - precision_6: 0.5111 - val_loss: 0.6950 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7057 - accuracy: 0.5065 - recall_6: 0.5574 - precision_6: 0.5170 - val_loss: 0.6949 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7052 - accuracy: 0.5010 - recall_6: 0.5471 - precision_6: 0.5121 - val_loss: 0.6950 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7048 - accuracy: 0.5046 - recall_6: 0.5442 - precision_6: 0.5156 - val_loss: 0.6950 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7052 - accuracy: 0.5069 - recall_6: 0.5653 - precision_6: 0.5172 - val_loss: 0.6951 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7060 - accuracy: 0.5065 - recall_6: 0.5650 - precision_6: 0.5168 - val_loss: 0.6954 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7066 - accuracy: 0.5046 - recall_6: 0.5734 - precision_6: 0.5148 - val_loss: 0.6953 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7102 - accuracy: 0.4976 - recall_6: 0.5623 - precision_6: 0.5088 - val_loss: 0.6952 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7073 - accuracy: 0.5042 - recall_6: 0.5688 - precision_6: 0.5145 - val_loss: 0.6949 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7095 - accuracy: 0.4899 - recall_6: 0.5404 - precision_6: 0.5020 - val_loss: 0.6948 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7074 - accuracy: 0.5044 - recall_6: 0.5477 - precision_6: 0.5154 - val_loss: 0.6949 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7082 - accuracy: 0.4946 - recall_6: 0.5444 - precision_6: 0.5063 - val_loss: 0.6949 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7061 - accuracy: 0.5032 - recall_6: 0.5647 - precision_6: 0.5138 - val_loss: 0.6949 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7076 - accuracy: 0.4979 - recall_6: 0.5685 - precision_6: 0.5090 - val_loss: 0.6951 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7096 - accuracy: 0.4994 - recall_6: 0.5712 - precision_6: 0.5103 - val_loss: 0.6950 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7096 - accuracy: 0.5019 - recall_6: 0.5693 - precision_6: 0.5125 - val_loss: 0.6948 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7068 - accuracy: 0.5105 - recall_6: 0.5674 - precision_6: 0.5204 - val_loss: 0.6947 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7072 - accuracy: 0.4967 - recall_6: 0.5380 - precision_6: 0.5083 - val_loss: 0.6945 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7015 - accuracy: 0.5136 - recall_6: 0.5601 - precision_6: 0.5236 - val_loss: 0.6945 - val_accuracy: 0.4925 - val_recall_6: 1.0000 - val_precision_6: 0.4925\n",
            "87/87 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5054 - recall_6: 1.0000 - precision_6: 0.5054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6940514445304871, 0.5053995847702026, 1.0, 0.5053995847702026]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***EXP 8***"
      ],
      "metadata": {
        "id": "d5bKnrY1BPCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "rlrop = ReduceLROnPlateau(monitor='accuracy', factor=0.1, patience=100)\n",
        "\n",
        "model_cnn4 = Sequential() \n",
        "model_cnn4.add(Conv1D(filters=160, kernel_size=2, activation='relu', input_shape=(110,3), kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model_cnn4.add(Conv1D(filters=128, kernel_size=2, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model_cnn4.add(Flatten())\n",
        "model_cnn4.add(Dropout(0.7))\n",
        "model_cnn4.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "\n",
        "model_cnn4.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "model_cnn4.summary()\n",
        "\n",
        "#_________\n",
        "model_cnn4.fit(train_x, train_y, epochs=50, batch_size=1000, verbose=1,callbacks=[rlrop])\n",
        "#________\n",
        "scores = model_cnn4.evaluate(test_x,test_y, verbose=1)\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VLVe0qcBOSS",
        "outputId": "e5364ab6-a628-4f18-91c9-4fec7e84e843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_16 (Conv1D)          (None, 109, 160)          1120      \n",
            "                                                                 \n",
            " conv1d_17 (Conv1D)          (None, 108, 128)          41088     \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 13824)             0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 13824)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 13825     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56,033\n",
            "Trainable params: 56,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 1s 15ms/step - loss: 2.0214 - accuracy: 0.5111 - recall_7: 0.5648 - precision_7: 0.5176 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.6722 - accuracy: 0.5154 - recall_7: 0.7569 - precision_7: 0.5160 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.4032 - accuracy: 0.5135 - recall_7: 0.3895 - precision_7: 0.5292 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1988 - accuracy: 0.5214 - recall_7: 0.5809 - precision_7: 0.5266 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0482 - accuracy: 0.5219 - recall_7: 0.6397 - precision_7: 0.5244 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9396 - accuracy: 0.5111 - recall_7: 0.4851 - precision_7: 0.5206 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8612 - accuracy: 0.5290 - recall_7: 0.6365 - precision_7: 0.5306 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8070 - accuracy: 0.5181 - recall_7: 0.8467 - precision_7: 0.5159 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7694 - accuracy: 0.5211 - recall_7: 0.8070 - precision_7: 0.5186 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7442 - accuracy: 0.5169 - recall_7: 0.8434 - precision_7: 0.5152 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7277 - accuracy: 0.5123 - recall_7: 0.9571 - precision_7: 0.5109 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7151 - accuracy: 0.5070 - recall_7: 0.7186 - precision_7: 0.5108 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7082 - accuracy: 0.5061 - recall_7: 0.3161 - precision_7: 0.5236 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7026 - accuracy: 0.5145 - recall_7: 0.6992 - precision_7: 0.5166 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6994 - accuracy: 0.5135 - recall_7: 0.7118 - precision_7: 0.5155 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6977 - accuracy: 0.5051 - recall_7: 0.3428 - precision_7: 0.5202 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6957 - accuracy: 0.5131 - recall_7: 0.8750 - precision_7: 0.5124 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6951 - accuracy: 0.5100 - recall_7: 0.9791 - precision_7: 0.5094 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6945 - accuracy: 0.5111 - recall_7: 0.5713 - precision_7: 0.5174 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6946 - accuracy: 0.4937 - recall_7: 0.0893 - precision_7: 0.5119 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6939 - accuracy: 0.5117 - recall_7: 0.8484 - precision_7: 0.5119 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6937 - accuracy: 0.5084 - recall_7: 0.9991 - precision_7: 0.5084 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6934 - accuracy: 0.5080 - recall_7: 0.9388 - precision_7: 0.5087 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6937 - accuracy: 0.5002 - recall_7: 0.2296 - precision_7: 0.5190 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6936 - accuracy: 0.5018 - recall_7: 0.2729 - precision_7: 0.5191 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5087 - recall_7: 0.9758 - precision_7: 0.5087 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5085 - recall_7: 1.0000 - precision_7: 0.5084 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5084 - recall_7: 1.0000 - precision_7: 0.5084 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6937 - accuracy: 0.5084 - recall_7: 1.0000 - precision_7: 0.5084 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5084 - recall_7: 1.0000 - precision_7: 0.5084 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5075 - recall_7: 0.9935 - precision_7: 0.5080 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5074 - recall_7: 0.9523 - precision_7: 0.5083 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5109 - recall_7: 0.9845 - precision_7: 0.5098 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5076 - recall_7: 0.9937 - precision_7: 0.5080 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5087 - recall_7: 0.9970 - precision_7: 0.5086 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5084 - recall_7: 0.9998 - precision_7: 0.5084 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5082 - recall_7: 0.9998 - precision_7: 0.5083 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5082 - recall_7: 0.9998 - precision_7: 0.5083 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5074 - recall_7: 0.9726 - precision_7: 0.5081 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5058 - recall_7: 0.9638 - precision_7: 0.5073 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5043 - recall_7: 0.9375 - precision_7: 0.5067 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5057 - recall_7: 0.6384 - precision_7: 0.5111 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5025 - recall_7: 0.7210 - precision_7: 0.5075 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5081 - recall_7: 0.8040 - precision_7: 0.5103 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5043 - recall_7: 0.7756 - precision_7: 0.5081 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5099 - recall_7: 0.9362 - precision_7: 0.5098 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5074 - recall_7: 0.9619 - precision_7: 0.5082 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5055 - recall_7: 0.7079 - precision_7: 0.5098 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.4981 - recall_7: 0.6428 - precision_7: 0.5050 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5035 - recall_7: 0.6996 - precision_7: 0.5085 - lr: 0.0010\n",
            "87/87 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5054 - recall_7: 1.0000 - precision_7: 0.5054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.693123996257782, 0.5053995847702026, 1.0, 0.5053995847702026]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.var(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP88tIjrEDTT",
        "outputId": "4c8f1c8f-3705-4158-fafc-75ab267f94f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          2.851896e+01\n",
              "1          2.810360e+01\n",
              "2          2.793930e+01\n",
              "3          2.801802e+01\n",
              "4          2.835883e+01\n",
              "               ...     \n",
              "2590443    8.387772e+11\n",
              "2590444    8.387778e+11\n",
              "2590445    8.387785e+11\n",
              "2590446    8.387791e+11\n",
              "2590447    8.387797e+11\n",
              "Length: 2590448, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "OutlierremovalALLSENSORSCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}